<!DOCTYPE html>
<html class="client-nojs" lang="en" dir="ltr">
<head>
<meta charset="UTF-8"/>
<title>BigStitcher Interest points - ImageJ</title>
<script>document.documentElement.className = document.documentElement.className.replace( /(^|\s)client-nojs(\s|$)/, "$1client-js$2" );</script>
<script>(window.RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgCanonicalNamespace":"","wgCanonicalSpecialPageName":false,"wgNamespaceNumber":0,"wgPageName":"BigStitcher_Interest_points","wgTitle":"BigStitcher Interest points","wgCurRevisionId":37389,"wgRevisionId":37389,"wgArticleId":9974,"wgIsArticle":true,"wgIsRedirect":false,"wgAction":"view","wgUserName":null,"wgUserGroups":["*"],"wgCategories":[],"wgBreakFrames":false,"wgPageContentLanguage":"en","wgPageContentModel":"wikitext","wgSeparatorTransformTable":["",""],"wgDigitTransformTable":["",""],"wgDefaultDateFormat":"dmy","wgMonthNames":["","January","February","March","April","May","June","July","August","September","October","November","December"],"wgMonthNamesShort":["","Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec"],"wgRelevantPageName":"BigStitcher_Interest_points","wgRelevantArticleId":9974,"wgRequestId":"5d9fc749fd73a9364a01683c","wgIsProbablyEditable":false,"wgRestrictionEdit":[],"wgRestrictionMove":[],"wgPreferredVariant":"en","fancytree_path":"/extensions/TreeAndMenu/fancytree"});mw.loader.state({"site.styles":"ready","noscript":"ready","user.styles":"ready","user.cssprefs":"ready","user":"ready","user.options":"loading","user.tokens":"loading","ext.math.styles":"ready","mediawiki.legacy.shared":"ready","mediawiki.legacy.commonPrint":"ready","mediawiki.sectionAnchor":"ready","skins.erudite":"ready"});mw.loader.implement("user.options@0j3lz3q",function($,jQuery,require,module){mw.user.options.set({"variant":"en"});});mw.loader.implement("user.tokens@1ku9xth",function ( $, jQuery, require, module ) {
mw.user.tokens.set({"editToken":"+\\","patrolToken":"+\\","watchToken":"+\\","csrfToken":"+\\"});/*@nomin*/;

});mw.loader.load(["mediawiki.page.startup"]);});</script>
<link rel="stylesheet" href="erudite5.css"/>
<link rel="stylesheet" href="extensions/TreeAndMenu/fancytree/fancytree.css"/><link rel="stylesheet" href="extensions/TreeAndMenu/suckerfish/suckerfish.css"/>
<meta name="ResourceLoaderDynamicStyles" content=""/>
<link rel="stylesheet" href="erudite15.css"/>
<meta name="generator" content="MediaWiki 1.28.0"/>
<meta name="description" content="Many processing steps of BigStitcher and Multiview-Reconstruction rely on the detection of Interest Points, i.e. bright or dark spots, in the images. The classical example is the alignment of multi-angle views by matching corresponding interest points in two images and aligning the points, and thus the images, to each other."/>
<link rel="shortcut icon" href="skins/ij2.ico"/>
	<meta property="og:type" content="article"/>

	<meta property="og:site_name" content="ImageJ"/>

	<meta property="og:title" content="BigStitcher Interest points"/>

	<meta property="og:description" content="Many processing steps of BigStitcher and Multiview-Reconstruction rely on the detection of Interest Points, i.e. bright or dark spots, in the images. The classical example is the alignment of multi-angle views by matching corresponding interest points in two images and aligning the points, and thus the images, to each other."/>


<meta name="viewport" content="width=device-width, initial-scale=1" />
</head>
<body class="mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject page-BigStitcher_Interest_points rootpage-BigStitcher_Interest_points skin-erudite action-view">
		<div id="top-wrap" role="banner">
			<h1><a href="Welcome" title="ImageJ" rel="home">ImageJ</a></h1>
			<div id="tagline">From ImageJ</div>

			<a id="menubutton" href="BigStitcher_Interest_points.html#menu">Menu</a>
			<div id="nav" role="navigation">
			<ul id='menu'>
<li id="menu-item-n-About"><a href="ImageJ">About</a></li>
<li id="menu-item-n-Downloads"><a href="Downloads">Downloads</a></li>
<li id="menu-item-n-Learn"><a href="Learn">Learn</a></li>
<li id="menu-item-n-Develop"><a href="Development">Develop</a></li>
<li id="menu-item-n-News"><a href="News">News</a></li>
<li id="menu-item-n-Events"><a href="Events">Events</a></li>
<li id="menu-item-n-Help"><a href="Help">Help</a></li>
</ul>
			</div>
		</div>

		<div id="mw-js-message"></div>
		
		<div id="main" role="main">

			<div id="bodyContent">
				<div style="font-size: large; border: 1px solid black; padding: 1em; margin-bottom: 1em; text-align: center; background-color: #fda;">
					This is an archive of the old MediaWiki-based ImageJ wiki. The current website can be found at <a href="https://imagej.net/">imagej.net</a>.
				</div>

				<h1>BigStitcher Interest points</h1>
				
				<div id="mw-content-text" lang="en" dir="ltr" class="mw-content-ltr"><div id="toc" class="toc"><div id="toctitle"><h2>Contents</h2></div>
<ul>
<li class="toclevel-1 tocsection-1"><a href="BigStitcher_Interest_points.html#Overview"><span class="tocnumber">1</span> <span class="toctext">Overview</span></a>
<ul>
<li class="toclevel-2 tocsection-2"><a href="BigStitcher_Interest_points.html#Basic_Parameters"><span class="tocnumber">1.1</span> <span class="toctext">Basic Parameters</span></a></li>
<li class="toclevel-2 tocsection-3"><a href="BigStitcher_Interest_points.html#Advanced_Parameters"><span class="tocnumber">1.2</span> <span class="toctext">Advanced Parameters</span></a></li>
<li class="toclevel-2 tocsection-4"><a href="BigStitcher_Interest_points.html#Interactive_detection_preview"><span class="tocnumber">1.3</span> <span class="toctext">Interactive detection preview</span></a></li>
<li class="toclevel-2 tocsection-5"><a href="BigStitcher_Interest_points.html#GPU-accelerated_Difference-of-Gaussian"><span class="tocnumber">1.4</span> <span class="toctext">GPU-accelerated Difference-of-Gaussian</span></a></li>
</ul>
</li>
</ul>
</div>

<h2><span class="mw-headline" id="Overview">Overview</span></h2>
<p>Many processing steps of BigStitcher and <a href="Multiview-Reconstruction" title="Multiview-Reconstruction">Multiview-Reconstruction</a> rely on the detection of <b>Interest Points</b>, i.e. bright or dark spots, in the images. The classical example is the alignment of multi-angle views by matching corresponding interest points in two images and aligning the points, and thus the images, to each other. 
</p><p>In <b>Multiview Mode</b>, interest point detection can be started by selecting the desired views, right-clicking and selecting the <span><em><span style="border-bottom:1px dotted #ccc;">Processing</span>&#160;&#8250; <span style="border-bottom:1px dotted #ccc;">Detect Interest Points...</span></em></span> option in the main menu.
</p><p>Other uses of interest points are:
</p>
<ul><li> Expert-mode stitching via Interest Points (click <a href="BigStitcher_Advanced_stitching#Interest_point-based_shift_calculation" title="BigStitcher Advanced stitching">here</a> for details)</li>
<li> Affine Refinement of Tile registrations and Chromatic aberration correction via ICP (click <a href="BigStitcher_ICP_refinement" title="BigStitcher ICP refinement">here</a> for details)</li></ul>
<p>Furthermore, detecting sub-diffraction-sized beads is the default way of extracting a <a href="BigStitcher_PSF" title="BigStitcher PSF">Point Spread Function (PSF)</a> for <a href="BigStitcher_Deconvolution" title="BigStitcher Deconvolution">(MultiView) Deconvolution</a>.
</p>
<h3><span class="mw-headline" id="Basic_Parameters">Basic Parameters</span></h3>
<p>In the first dialog, you can select the detection method and give a <b>label</b> to interest points that will be detected (e.g "beads" or "nuclei").
</p><p>The <b>type of interest point detection</b> can be:
</p>
<ul><li><b>Difference-of-Mean (Integral image based):</b> slightly faster, but slightly less accurate</li>
<li><b>Difference-of-Gaussian:</b> more accurate, but slightly slower (can be GPU-accelerated with some work, however)</li></ul>
<p>You can activate some advanced parameterization by selecting <b>Define anisotropy for segmentation</b>, <b>Set minimal and maximal intensity</b> or <b>Limit amount of detections</b>. This will unlock additional options in the next dialog (see below for detailed explanations).
</p><p>If the views you selected contain multiple <i>tiles</i> or <i>illumination directions</i>, you can choose to <b>group</b> the views. The same minimum and maximum intensity will be used for all views in a group (see explanation below). This will virtually fuse the views into one image for the interest point detection preview, which can be very time consuming if you are not using a multi-resolution ImgLoader (i.e. if you have not re-saved the data as HDF5).
</p>
<div class="center"><div class="floatnone"><div class="MediaTransformError" style="width: 498px; height: 0px; display:inline-block;">Error creating thumbnail: Unable to save thumbnail to destination</div></div></div>
<h3><span class="mw-headline" id="Advanced_Parameters">Advanced Parameters</span></h3>
<p>In the next dialog, you will be asked for some more parameters for the interest point detection.
</p><p>Under <b>Subpixel localization</b>, you can select whether to do subpixel-accurate detection of interest points using a 3-dimensional quadratic fit or not (the third option <i>Gaussian mask localization fit</i> is not implemented yet at the moment).
</p><p><b>Interest point specification</b> determines the size and threshold of spots for which to look. There are some presets, as well as:
</p>
<ul><li> <b>Advanced ...</b>, which lets you manually set the values for threshold and sigma/radius.</li>
<li> <b>Interactive...</b>, which lets you interactively change the values and display a preview of detections.</li></ul>
<p>Next, you can choose to <b>downsample</b> your images (or use precomputed downsampled versions) to significantly speed up the interest point detection. Note that if you downsample a lot, you should use subpixel localization to counteract the corresponding inaccuracy.
</p><p>If you chose to <b>Set minimal and maximal intensity</b> in the previous dialog, you will be asked for those values here. Their meaning is the following: If you do NOT set the minimum and maximum, the threshold you will select in the next step is relative to the min/max of <i>each individual image</i>. This might lead to more false positive and false negative detections if the individual images vary in brightness. Setting <b>Minimal intensity</b> and <b>Maximal intensity</b> causes the same values to be used for <i>ALL images</i> and counteract these problems. Note that if you chose to <b>group</b> views earlier, the minimum and maximum of the whole group will be used for each image in the group.
</p><p>If you chose to <b>Define anisotropy for segmentation</b> in the previous dialog, you will be asked for <b>Image sigmas in X, Y and Z</b> here. If you acquired your images with pixel sizes and z-spacing of <img class="mwe-math-fallback-image-inline tex" alt="\approx \frac{d}{2}" src="images/math/2/f/1/2f10dd97d5cf7eda7798f94cc07e399d.png" /> (optimal sampling) with <img class="mwe-math-fallback-image-inline tex" alt="d" src="images/math/8/2/7/8277e0910d750195b448797616e091ad.png" /> being the resolution of you microscope (<img class="mwe-math-fallback-image-inline tex" alt="d_{xy} = \frac{\lambda}{2NA}" src="images/math/c/6/b/c6b5d2d420e52d69b23007b9aa52d3b9.png" /> and <img class="mwe-math-fallback-image-inline tex" alt="d_{z} = \frac{2\lambda}{NA^2}" src="images/math/1/b/f/1bf30c6f9484bb29568ee2c2e05fedcb.png" />), you can leave the default value of 0.5 here. Otherwise, increase the image sigma when you have <i>oversampling</i> (smaller pixel distances) or decrease it for <i>undersampling</i> (larger pixels). Note that it is only necessary to change the image sigmas if you over- or undersample differently in x,y and z. If you over- or undersampled by the same factor in x,y and z, you can also ignore these parameters and just set sigma/radius accordingly in the next step.
</p><p>If you chose to <b>Limit amount of detections</b> in the previous dialog, you will be asked for the <b>Maximum number of detections (highest n)</b> to keep and which <b>Type of detections to use</b>. This can be:
</p>
<ul><li> <b>Brightest</b>: keep only the "brightest" detections (highest maxima or lowest minima).</li>
<li> <b>Weakest (above threshold)</b>: keep only the "weakest" detections that were not excluded via the threshold (lowest maxima or highest minima)</li>
<li> <b>Around median (of those above threshold)</b>: keep only the detections closest to the median absolute intensity (of the detections above the threshold)</li></ul>
<p>Finally, when doing Difference-of-Gaussian detection, you can choose whether to compute the necessary convolution operations on the CPU or a GPU under <b>"Compute on"</b>. 
GPU-accelerated detection requires a CUDA-capable NVIDA graphics card.
You also have to compile the <a href="Multiview-Reconstruction#Download" title="Multiview-Reconstruction">required libraries</a> for your system first (see the corresponding GitHib pages for details).
There is an <i>approximate</i> and an <i>accurate</i> version of the GPU-accelerated convolutions - the <i>approximate</i> version is slightly faster but might produce some artifacts around the edges of your images.
</p>
<div class="center"><div class="floatnone"><a href="./File:BigStitcher_Register_2.png" class="image"><img alt="BigStitcher Register 2.png" src="images/4/44/BigStitcher_Register_2.png" width="600" height="479" /></a></div></div>
<h3><span class="mw-headline" id="Interactive_detection_preview">Interactive detection preview</span></h3>
<p>If you opted for <b>Interactive Interest point specification</b> in the previous dialog, you will first be asked for one view (or view group) in which to preview the detection.
</p><p>If you are using <b>grouped views</b>, you can specify how much percentage in z of the image should be displayed in the preview using the sliders.
</p><p>Furthermore, if you are using <b>grouped views</b>, you can choose to <b>Use min/max of this fusion for all groups</b> (see above for details about the meaning of the min/max values).
</p>
<div class="center"><div class="floatnone"><div class="MediaTransformError" style="width: 461px; height: 0px; display:inline-block;">Error creating thumbnail: Unable to save thumbnail to destination</div></div></div>
<p>If you click OK, the (fused) image will appear in an ImageJ-window together with a window in which the values for the interest point detection parameters can be specified. You can change <b>Sigma 1</b> (Difference-of-Gaussian) or <b>Radius 1</b> (Difference-of-Mean) to specify the size of objects to look as well as the <b>Threshold</b> (intensity of objects to look for) and whether to look for minima, maxima or both. The results will be previewed in the ImageJ-window. You can interactively go through the Z-stack and preview the detected interest points. To start the detection process in all selected views, click "Done".
</p>
<div style="overflow:hidden"><table class="metadata plainlinks ambox ambox-notice">
<tr>
<td class="ambox-image">
<p><a href="./File:Information-sign.png" class="image"><img alt="Information-sign.png" src="images/2/24/Information-sign.png" width="40" height="40" /></a>
</p>
</td>
<td> The interest point detection can take a long time, especially if you do little or no downsampling. Have a look at the log widow for updates on the progress. </td>
<p><br />
</p>
</tr>
</table></div>
<p><br />
</p>
<div class="MediaTransformError" style="width: 386px; height: 0px; display:inline-block;">Error creating thumbnail: Unable to save thumbnail to destination</div><div class="MediaTransformError" style="width: 791px; height: 0px; display:inline-block;">Error creating thumbnail: Unable to save thumbnail to destination</div>
<h3><span class="mw-headline" id="GPU-accelerated_Difference-of-Gaussian">GPU-accelerated Difference-of-Gaussian</span></h3>
<p>If you chose to use GPU-accelerated detection and compiled the library for separable convolution from [<a rel="nofollow" class="external autonumber" href="https://github.com/StephanPreibisch/SeparableConvolutionCUDALib">[1]</a>], you will have to go through a few more steps until the interest point detection starts.
</p><p>First, you have to specify the <b>CUDA directory</b> in which to look for the compiled library (an .so file on Linux/Mac or a .dll on Windows).
</p>
<div class="center"><div class="floatnone"><div class="MediaTransformError" style="width: 843px; height: 0px; display:inline-block;">Error creating thumbnail: Unable to save thumbnail to destination</div></div></div>
<p>Next, you have to select the actual library file to use (there might be multiple, be sure to pick the library for <b>separable convolution</b>, not the <i>Fourier convolution</i> used in <a href="Multi-View_Deconvolution" title="Multi-View Deconvolution">Multi-View_Deconvolution</a>).
</p>
<div class="center"><div class="floatnone"><div class="MediaTransformError" style="width: 562px; height: 0px; display:inline-block;">Error creating thumbnail: Unable to save thumbnail to destination</div></div></div>
<p>In the last dialog, you can choose which <b>Device</b> (GPU) to use (if you have multiple) and how many <b>Percent of GPU Memory to use</b>. We advice to stick to ~80 percent to avoid collisions with other processes that might be using the GPU.
</p><p>Click <b>OK</b> once more to start the interest point detection.
</p>
<div class="center"><div class="floatnone"><div class="MediaTransformError" style="width: 826px; height: 0px; display:inline-block;">Error creating thumbnail: Unable to save thumbnail to destination</div></div></div>
<p>Go back to the <a href="BigStitcher#Documentation" title="BigStitcher">main page</a>
</p>
<!-- 
NewPP limit report
Cached time: 20200713064618
Cache expiry: 86400
Dynamic content: false
CPU time usage: 0.040 seconds
Real time usage: 0.043 seconds
Preprocessor visited node count: 147/1000000
Preprocessor generated node count: 871/1000000
Post‐expand include size: 1125/2097152 bytes
Template argument size: 384/2097152 bytes
Highest expansion depth: 6/40
Expensive parser function count: 0/3
-->

<!-- 
Transclusion expansion time report (%,ms,calls,template)
100.00%   14.258      1 - -total
 28.89%    4.119      1 - Template:Bc
 18.62%    2.655      1 - Template:Notice
 13.00%    1.854      1 - Template:Ambox
  6.83%    0.974      1 - Template:Arrow
-->
</div><div class="printfooter">
Retrieved from "<a dir="ltr" href="index.php?title=BigStitcher_Interest_points&amp;oldid=37389">http://imagej.net/index.php?title=BigStitcher_Interest_points&amp;oldid=37389</a>"</div>
							</div>

			<div id="footer">
				<p> This page was last modified on 23 March 2018, at 08:13.</p><ul><li><a href="./ImageJ:Privacy_policy" title="ImageJ:Privacy policy">Privacy policy</a></li><li><a href="./ImageJ:About" class="mw-redirect" title="ImageJ:About">About ImageJ</a></li><li><a href="Imprint" title="Imprint">Imprint</a></li></ul>			</div>

			<div id="catlinks" class="catlinks catlinks-allhidden" data-mw="interface"></div>		</div>

		<div id="bottom-wrap">
			<div id="footer-wrap-inner">
				<div id="ternary" class="footer">
					<ul>
						<li class="widget">
							<img id="logo" src="skins/imagej-128.png" alt="">
						</li>
					</ul>
				</div>
			</div>
		</div>
		<script>(window.RLQ=window.RLQ||[]).push(function(){mw.loader.load(["ext.fancytree","ext.suckerfish","mediawiki.toc","mediawiki.action.view.postEdit","site","mediawiki.user","mediawiki.hidpi","mediawiki.page.ready","mediawiki.searchSuggest","ext.SimpleTooltip"]);});</script><script>(window.RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgBackendResponseTime":220});});</script>
		</body>
		</html>
		