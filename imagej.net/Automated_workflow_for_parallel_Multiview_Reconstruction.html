<!DOCTYPE html>
<html class="client-nojs" lang="en" dir="ltr">
<head>
<meta charset="UTF-8"/>
<title>Automated workflow for parallel Multiview Reconstruction - ImageJ</title>
<script>document.documentElement.className = document.documentElement.className.replace( /(^|\s)client-nojs(\s|$)/, "$1client-js$2" );</script>
<script>(window.RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgCanonicalNamespace":"","wgCanonicalSpecialPageName":false,"wgNamespaceNumber":0,"wgPageName":"Automated_workflow_for_parallel_Multiview_Reconstruction","wgTitle":"Automated workflow for parallel Multiview Reconstruction","wgCurRevisionId":19613,"wgRevisionId":19613,"wgArticleId":2933,"wgIsArticle":true,"wgIsRedirect":false,"wgAction":"view","wgUserName":null,"wgUserGroups":["*"],"wgCategories":["Transform","Registration","Deconvolution"],"wgBreakFrames":false,"wgPageContentLanguage":"en","wgPageContentModel":"wikitext","wgSeparatorTransformTable":["",""],"wgDigitTransformTable":["",""],"wgDefaultDateFormat":"dmy","wgMonthNames":["","January","February","March","April","May","June","July","August","September","October","November","December"],"wgMonthNamesShort":["","Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec"],"wgRelevantPageName":"Automated_workflow_for_parallel_Multiview_Reconstruction","wgRelevantArticleId":2933,"wgRequestId":"446f67f4def6864157b6e12c","wgIsProbablyEditable":false,"wgRestrictionEdit":[],"wgRestrictionMove":[],"wgPreferredVariant":"en","fancytree_path":"/extensions/TreeAndMenu/fancytree"});mw.loader.state({"site.styles":"ready","noscript":"ready","user.styles":"ready","user.cssprefs":"ready","user":"ready","user.options":"loading","user.tokens":"loading","mediawiki.legacy.shared":"ready","mediawiki.legacy.commonPrint":"ready","mediawiki.sectionAnchor":"ready","skins.erudite":"ready"});mw.loader.implement("user.options@0j3lz3q",function($,jQuery,require,module){mw.user.options.set({"variant":"en"});});mw.loader.implement("user.tokens@1ku9xth",function ( $, jQuery, require, module ) {
mw.user.tokens.set({"editToken":"+\\","patrolToken":"+\\","watchToken":"+\\","csrfToken":"+\\"});/*@nomin*/;

});mw.loader.load(["mediawiki.page.startup"]);});</script>
<link rel="stylesheet" href="load.php%3Fdebug=false&amp;lang=en&amp;modules=mediawiki.legacy.commonPrint%252Cshared%257Cmediawiki.sectionAnchor%257Cskins.erudite&amp;only=styles&amp;skin=erudite.css"/>
<script async="" src="load.php%3Fdebug=false&amp;lang=en&amp;modules=startup&amp;only=scripts&amp;skin=erudite"></script>
<link rel="stylesheet" href="extensions/TreeAndMenu/fancytree/fancytree.css"/><link rel="stylesheet" href="extensions/TreeAndMenu/suckerfish/suckerfish.css"/>
<meta name="ResourceLoaderDynamicStyles" content=""/>
<link rel="stylesheet" href="load.php%3Fdebug=false&amp;lang=en&amp;modules=site.styles&amp;only=styles&amp;skin=erudite.css"/>
<meta name="generator" content="MediaWiki 1.28.0"/>
<meta name="description" content="Please note that the automated workflow for processing SPIM data on a cluster is based on a publication. If you use it successfully for your research please be so kind to cite the following work:"/>
<link rel="shortcut icon" href="skins/ij2.ico"/>

<script type="text/javascript" src="extensions/SyntaxHighlighter/syntaxhighlighter/scripts/shCore.js"></script>
<script type="text/javascript" src="extensions/SyntaxHighlighter/syntaxhighlighter/scripts/shBrushBash.js"></script>
<script type="text/javascript">
SyntaxHighlighter.all();
</script>
<link rel="stylesheet" type="text/css" media="screen" href="extensions/SyntaxHighlighter/syntaxhighlighter/styles/shCoreMinit.css" />

	<meta property="og:type" content="article"/>

	<meta property="og:site_name" content="ImageJ"/>

	<meta property="og:title" content="Automated workflow for parallel Multiview Reconstruction"/>

	<meta property="og:description" content="Please note that the automated workflow for processing SPIM data on a cluster is based on a publication. If you use it successfully for your research please be so kind to cite the following work:"/>


<meta name="viewport" content="width=device-width, initial-scale=1" />
</head>
<body class="mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject page-Automated_workflow_for_parallel_Multiview_Reconstruction rootpage-Automated_workflow_for_parallel_Multiview_Reconstruction skin-erudite action-view">
		<div class="mw-jump">
			<a href="Automated_workflow_for_parallel_Multiview_Reconstruction.html#bodyContent">Skip to content</a>, 			<a href="Automated_workflow_for_parallel_Multiview_Reconstruction.html#search">Skip to search</a>
		</div>

		<div id="top-wrap" role="banner">
			<h1><a href="Welcome" title="ImageJ" rel="home">ImageJ</a></h1>
			<div id="tagline">From ImageJ</div>

			<a id="menubutton" href="Automated_workflow_for_parallel_Multiview_Reconstruction.html#menu">Menu</a>
			<div id="nav" role="navigation">
			<ul id='menu'>
<li id="menu-item-n-About"><a href="ImageJ">About</a></li>
<li id="menu-item-n-Downloads"><a href="Downloads">Downloads</a></li>
<li id="menu-item-n-Learn"><a href="Learn">Learn</a></li>
<li id="menu-item-n-Develop"><a href="Development">Develop</a></li>
<li id="menu-item-n-News"><a href="News">News</a></li>
<li id="menu-item-n-Events"><a href="Events">Events</a></li>
<li id="menu-item-n-Help"><a href="Help">Help</a></li>
</ul>
			</div>
		</div>

		<div id="mw-js-message"></div>
		
		<div id="main" role="main">

			<div id="bodyContent">
				<h1>Automated workflow for parallel Multiview Reconstruction</h1>
				
				<div id="mw-content-text" lang="en" dir="ltr" class="mw-content-ltr"><table class="infobox" cellspacing="5" style="max-width: 31em; font-size: 90%; text-align: left; float: right; border: 1px solid #a0a0a0;">
<tr>
<th colspan="2" style="text-align: center; font-size: 130%;"> <div style="float: left"></div>An automated workflow for parallel processing of large multiview SPIM recordings (Fiji)<div style="clear: left;"></div>
</th></tr>
<tr>
<th> Author
</th>
<td> <a rel="nofollow" class="external text" href="https://de.linkedin.com/in/christopher-schmied-75882b101">Christopher Schmied</a>, Peter Steinbach, Pavel Tomancak
</td></tr>




<tr>
<th> Maintainer
</th>
<td> <a rel="nofollow" class="external text" href="https://de.linkedin.com/in/christopher-schmied-75882b101">Christopher Schmied</a>
</td></tr>


<tr>
<th> Source
</th>
<td> <a rel="nofollow" class="external text" href="https://github.com/mpicbg-scicomp/snakemake-workflows">on github</a>
</td></tr>
<tr>
<th> Initial release
</th>
<td> July 2015
</td></tr>
<tr>
<th> Latest version
</th>
<td> March 2016
</td></tr>

<tr>
<th> Category
</th>
<td> <a href="./Category:Transform" title="Category:Transform">Transform</a>, <a href="./Category:Registration" title="Category:Registration">Registration</a>, <a href="./Category:Deconvolution" title="Category:Deconvolution">Deconvolution</a>
</td></tr>

</table>
<p><br />
</p>
<div id="toc" class="toc"><div id="toctitle"><h2>Contents</h2></div>
<ul>
<li class="toclevel-1 tocsection-1"><a href="Automated_workflow_for_parallel_Multiview_Reconstruction.html#Citation"><span class="tocnumber">1</span> <span class="toctext">Citation</span></a></li>
<li class="toclevel-1 tocsection-2"><a href="Automated_workflow_for_parallel_Multiview_Reconstruction.html#Multiview_reconstruction"><span class="tocnumber">2</span> <span class="toctext">Multiview reconstruction</span></a></li>
<li class="toclevel-1 tocsection-3"><a href="Automated_workflow_for_parallel_Multiview_Reconstruction.html#Logic_of_workflow"><span class="tocnumber">3</span> <span class="toctext">Logic of workflow</span></a></li>
<li class="toclevel-1 tocsection-4"><a href="Automated_workflow_for_parallel_Multiview_Reconstruction.html#Supported_datasets"><span class="tocnumber">4</span> <span class="toctext">Supported datasets</span></a></li>
<li class="toclevel-1 tocsection-5"><a href="Automated_workflow_for_parallel_Multiview_Reconstruction.html#Fiji_for_workflow"><span class="tocnumber">5</span> <span class="toctext">Fiji for workflow</span></a></li>
<li class="toclevel-1 tocsection-6"><a href="Automated_workflow_for_parallel_Multiview_Reconstruction.html#Snakemake_for_workflow"><span class="tocnumber">6</span> <span class="toctext">Snakemake for workflow</span></a></li>
<li class="toclevel-1 tocsection-7"><a href="Automated_workflow_for_parallel_Multiview_Reconstruction.html#Automated_Multiview_Reconstruction_workflow"><span class="tocnumber">7</span> <span class="toctext">Automated Multiview Reconstruction workflow</span></a>
<ul>
<li class="toclevel-2 tocsection-8"><a href="Automated_workflow_for_parallel_Multiview_Reconstruction.html#timelapse_directory"><span class="tocnumber">7.1</span> <span class="toctext">timelapse directory</span></a></li>
<li class="toclevel-2 tocsection-9"><a href="Automated_workflow_for_parallel_Multiview_Reconstruction.html#tools_directory"><span class="tocnumber">7.2</span> <span class="toctext">tools directory</span></a></li>
<li class="toclevel-2 tocsection-10"><a href="Automated_workflow_for_parallel_Multiview_Reconstruction.html#cluster_tools_directory"><span class="tocnumber">7.3</span> <span class="toctext">cluster_tools directory</span></a></li>
<li class="toclevel-2 tocsection-11"><a href="Automated_workflow_for_parallel_Multiview_Reconstruction.html#sysconfcpus"><span class="tocnumber">7.4</span> <span class="toctext">sysconfcpus</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-12"><a href="Automated_workflow_for_parallel_Multiview_Reconstruction.html#Command_line"><span class="tocnumber">8</span> <span class="toctext">Command line</span></a></li>
<li class="toclevel-1 tocsection-13"><a href="Automated_workflow_for_parallel_Multiview_Reconstruction.html#Initial_setup_of_the_workflow"><span class="tocnumber">9</span> <span class="toctext">Initial setup of the workflow</span></a></li>
<li class="toclevel-1 tocsection-14"><a href="Automated_workflow_for_parallel_Multiview_Reconstruction.html#Setup_for_the_dataset"><span class="tocnumber">10</span> <span class="toctext">Setup for the dataset</span></a>
<ul>
<li class="toclevel-2 tocsection-15"><a href="Automated_workflow_for_parallel_Multiview_Reconstruction.html#config.yaml"><span class="tocnumber">10.1</span> <span class="toctext"><i>config.yaml</i></span></a></li>
<li class="toclevel-2 tocsection-16"><a href="Automated_workflow_for_parallel_Multiview_Reconstruction.html#Setting_up_the_config.yaml_file_for_processing"><span class="tocnumber">10.2</span> <span class="toctext">Setting up the <i>config.yaml</i> file for processing</span></a>
<ul>
<li class="toclevel-3 tocsection-17"><a href="Automated_workflow_for_parallel_Multiview_Reconstruction.html#Processing_switches"><span class="tocnumber">10.2.1</span> <span class="toctext">Processing switches</span></a></li>
<li class="toclevel-3 tocsection-18"><a href="Automated_workflow_for_parallel_Multiview_Reconstruction.html#General_Settings"><span class="tocnumber">10.2.2</span> <span class="toctext">General Settings</span></a>
<ul>
<li class="toclevel-4 tocsection-19"><a href="Automated_workflow_for_parallel_Multiview_Reconstruction.html#Settings_for_.czi_files"><span class="tocnumber">10.2.2.1</span> <span class="toctext">Settings for .czi files</span></a></li>
<li class="toclevel-4 tocsection-20"><a href="Automated_workflow_for_parallel_Multiview_Reconstruction.html#Settings_for_.tif_datasets"><span class="tocnumber">10.2.2.2</span> <span class="toctext">Settings for .tif datasets</span></a></li>
</ul>
</li>
<li class="toclevel-3 tocsection-21"><a href="Automated_workflow_for_parallel_Multiview_Reconstruction.html#Detection_and_registration"><span class="tocnumber">10.2.3</span> <span class="toctext">Detection and registration</span></a></li>
<li class="toclevel-3 tocsection-22"><a href="Automated_workflow_for_parallel_Multiview_Reconstruction.html#Timelapse_registration"><span class="tocnumber">10.2.4</span> <span class="toctext">Timelapse registration</span></a></li>
<li class="toclevel-3 tocsection-23"><a href="Automated_workflow_for_parallel_Multiview_Reconstruction.html#Weighted-average_fusion"><span class="tocnumber">10.2.5</span> <span class="toctext">Weighted-average fusion</span></a></li>
<li class="toclevel-3 tocsection-24"><a href="Automated_workflow_for_parallel_Multiview_Reconstruction.html#Multiview_deconvolution"><span class="tocnumber">10.2.6</span> <span class="toctext">Multiview deconvolution</span></a>
<ul>
<li class="toclevel-4 tocsection-25"><a href="Automated_workflow_for_parallel_Multiview_Reconstruction.html#External_transformation"><span class="tocnumber">10.2.6.1</span> <span class="toctext">External transformation</span></a></li>
<li class="toclevel-4 tocsection-26"><a href="Automated_workflow_for_parallel_Multiview_Reconstruction.html#Deconvolution_settings"><span class="tocnumber">10.2.6.2</span> <span class="toctext">Deconvolution settings</span></a></li>
</ul>
</li>
<li class="toclevel-3 tocsection-27"><a href="Automated_workflow_for_parallel_Multiview_Reconstruction.html#Software_directories"><span class="tocnumber">10.2.7</span> <span class="toctext">Software directories</span></a></li>
<li class="toclevel-3 tocsection-28"><a href="Automated_workflow_for_parallel_Multiview_Reconstruction.html#Fiji_Resource_settings"><span class="tocnumber">10.2.8</span> <span class="toctext">Fiji Resource settings</span></a></li>
<li class="toclevel-3 tocsection-29"><a href="Automated_workflow_for_parallel_Multiview_Reconstruction.html#Advanced_settings"><span class="tocnumber">10.2.9</span> <span class="toctext">Advanced settings</span></a></li>
</ul>
</li>
<li class="toclevel-2 tocsection-30"><a href="Automated_workflow_for_parallel_Multiview_Reconstruction.html#cluster.json"><span class="tocnumber">10.3</span> <span class="toctext"><i>cluster.json</i></span></a></li>
<li class="toclevel-2 tocsection-31"><a href="Automated_workflow_for_parallel_Multiview_Reconstruction.html#Submitting_Jobs"><span class="tocnumber">10.4</span> <span class="toctext">Submitting Jobs</span></a></li>
<li class="toclevel-2 tocsection-32"><a href="Automated_workflow_for_parallel_Multiview_Reconstruction.html#Log_files_and_supervision_of_the_pipeline"><span class="tocnumber">10.5</span> <span class="toctext">Log files and supervision of the pipeline</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-33"><a href="Automated_workflow_for_parallel_Multiview_Reconstruction.html#Cluster"><span class="tocnumber">11</span> <span class="toctext">Cluster</span></a></li>
</ul>
</div>

<h1><span class="mw-headline" id="Citation">Citation</span></h1>
<p>Please note that the automated workflow for processing SPIM data on a cluster is based on a publication. If you use it successfully for your research please be so kind to cite the following work:
</p>
<ul><li>C. Schmied, P. Steinbach, T. Pietzsch, S. Preibisch, P. Tomancak (2015) "An automated workflow for parallel processing of large multiview SPIM recordings." <i>Bioinformatics</i>, Dec 1; doi: 10.1093/bioinformatics/btv706 <a rel="nofollow" class="external text" href="http://bioinformatics.oxfordjournals.org/content/early/2015/12/30/bioinformatics.btv706.long">Webpage</a></li></ul>
<p><br />
The automated workflow is based on the Fiji plugins <b><a href="Multiview-Reconstruction" title="Multiview-Reconstruction">Multiview Reconstruction</a></b> and <b><a href="BigDataViewer" title="BigDataViewer">BigDataViewer</a></b>. Please refer to and cite the following publications:
</p>
<ul><li> S. Preibisch, S. Saalfeld, J. Schindelin and P. Tomancak (2010) "Software for bead-based registration of selective plane illumination microscopy data", <i>Nature Methods</i>, <b>7</b>(6):418-419.<a rel="nofollow" class="external text" href="http://www.nature.com/nmeth/journal/v7/n6/full/nmeth0610-418.html">Webpage</a> </li>
<li> S. Preibisch, F. Amat, E. Stamataki, M. Sarov, R.H. Singer, E. Myers and P. Tomancak (2014) "Efficient Bayesian-based Multiview Deconvolution", <i>Nature Methods</i>, <b>11</b>(6):645-648. <a rel="nofollow" class="external text" href="http://www.nature.com/nmeth/journal/v11/n6/full/nmeth.2929.html">Webpage</a></li>
<li>T. Pietzsch, S. Saalfeld, S. Preibisch, P. Tomancak (2015) "BigDataViewer: visualization and processing for large image data sets." <i>Nature Methods</i>, <b>12</b>(6)481–483. <a rel="nofollow" class="external text" href="http://www.nature.com/nmeth/journal/v12/n6/full/nmeth.3392.html">Webpage</a></li></ul>
<h1><span class="mw-headline" id="Multiview_reconstruction">Multiview reconstruction</span></h1>
<p>In the <b><a href="Multiview-Reconstruction" title="Multiview-Reconstruction">Multiview Reconstruction</a></b> (MVR) pipeline all results are written into an XML. This poses new problems for cluster processing, because several concurrently running jobs need to update the same file. 
</p><p>Stephan Preibisch solved that problem by allowing to write one XML file per job (usually a timepoint) and then merging the job specific XMLs into one XML for the entire dataset. 
</p><p>In practice it means the following steps need to be executed:
</p>
<ul><li> Define XML dataset - creates one XML for the entire timelapse</li>
<li> Re-save data as HDF5 - converts data into HDF5 container optimised for fast access in <b><a href="BigDataViewer" title="BigDataViewer">BigDataViewer</a></b></li>
<li> Run per time-point registrations - creates as many XMLs as there are timepoints</li>
<li> Merge XMLs - consolidates the per-timepoint XMLs back into a single XML</li></ul>
<p>Some new parameters are introduced and some old parameters change names. Therefore, use the <i><b><a href="Automated_workflow_for_parallel_Multiview_Reconstruction.html#config.yaml">config.yaml</a></b></i> described in this chapter to process with the MVR pipeline.
</p><p>Outdated versions of the cluster processing scripts on which this workflow is based on you can find <a href="SPIM_Registration_on_cluster" class="mw-redirect" title="SPIM Registration on cluster">here</a>
</p>
<h1><span class="mw-headline" id="Logic_of_workflow">Logic of workflow</span></h1>
<p>We map and dispatch the workflow logic either on a single maschine or on a HPC cluster using the automated workflow engine <b><a rel="nofollow" class="external text" href="https://bitbucket.org/johanneskoester/snakemake/wiki/Home.">Snakemake</a></b>.
Within the <i>Snakefile</i> the workflow with the processing steps and the input and output rules is defined. Each of these steps call a Fiji <i>beanshell</i> script. These scripts in turn drive the processing via Fiji.
</p><p>The current workflow consists of the following steps. It covers the prinicipal processing for timelapse multiview SPIM processing:
</p><p>1. define czi or tif dataset.
</p><p>2. resave into hdf5.
</p><p>3. detect and register interest points.
</p><p>4. merge xml, creates XML for registered dataset. 
</p><p>5. timelapse registration.
</p><p>6. optional for dual channel dataset: duplicate transformations
</p><p>7. optional for deconvolution: external transformation
</p><p>8. average-weight fusion/deconvolution
</p><p>9. define output
</p><p>10. resave output into hdf5, creates XML for fused dataset.
</p>
<h1><span class="mw-headline" id="Supported_datasets">Supported datasets</span></h1>
<p>The scripts are supporting multiple angles, multiple channels and multiple illumination direction without adjusting the Snakefile or .bsh scripts.
</p><p>Using spimdata version: 0.9-revision
</p><p>Using SPIM registration version 2.3.9
</p><p>Supported datasets are in the following format:
</p><p>Using Zeiss Lightsheet Z.1 Dataset (LOCI)
</p>
<pre>   Multiple timepoints:  YES (one file per timepoint) or (all time-points in one file)
   Multiple channels:  YES (one file per channel) or (all channels in one file)
   Multiple illumination directions: YES (one file per illumination direction)
   Multiple angles: YES (one file per angle)
   
</pre>
<p>Using LOCI Bioformats opener (.tif)
</p>
<pre>   Multiple timepoints: YES (one file per timepoint) or (all time-points in one file)
   Multiple channels: YES (one file per channel) or (all channels in one file)
   Multiple illumination directions: YES (one file per illumination direction) =&gt; not tested yet
   Multiple angles: YES (one file per angle)
   
</pre>
<p>Using ImageJ Opener (.tif):
</p>
<pre>   Multiple timepoints: YES (one file per timepoint)
   Multiple channels: YES (one file per channel)
   Multiple illumination directions: YES (one file per illumination direction) =&gt; not tested yet
   Multiple angles: YES (one file per angle)
</pre>
<h1><span class="mw-headline" id="Fiji_for_workflow">Fiji for workflow</span></h1>
<p>You can download a Fiji version that we have tested for compatibility with the automated cluster processing here:
</p><p><b><a rel="nofollow" class="external free" href="http://tomancak-srv1.mpi-cbg.de/~schmied/">http://tomancak-srv1.mpi-cbg.de/~schmied/</a></b>
</p><p>It is important to note that we can only guarantee the proper execution of the workflow with the provided Fiji version. We will from time to time upgrade to cover the latest changes in the plugins.
</p>
<h1><span class="mw-headline" id="Snakemake_for_workflow">Snakemake for workflow</span></h1>
<p><b><a rel="nofollow" class="external text" href="https://bitbucket.org/snakemake/snakemake/wiki/Home">Snakemake</a></b> (command-line workflow engine) is used to automatically execute individual steps in the workflow. The workflow documented on this page was tested with snakemake 3.3 (interfaced with <b><a rel="nofollow" class="external text" href="http://www.pyyaml.org">PyYAML</a></b>(version 3.11) and <b><a rel="nofollow" class="external text" href="https://github.com/pygridtools/drmaa-python">python drmaa</a></b>(version 0.7.6) support.
</p>
<h1><span class="mw-headline" id="Automated_Multiview_Reconstruction_workflow">Automated Multiview Reconstruction workflow</span></h1>
<p>Clone the repository for the workflow from  <b><a rel="nofollow" class="external text" href="https://github.com/mpicbg-scicomp/snakemake-workflows">github</a></b>.
</p>
<pre class="brush:bash">
git clone https://github.com/mpicbg-scicomp/snakemake-workflows.git
</pre>
<p>The repository contains the example configuration scripts for single and dual channel datasets, the Snakefile which defines the workflow, the beanshell scripts which drive the processing via Fiji and a cluster.json file which contains information for the cluster queuing system.
</p>
<h2><span class="mw-headline" id="timelapse_directory">timelapse directory</span></h2>
<pre class="brush:bash">
/path/to/repository/spim_registration/timelapse/
├── README.md
├── Snakefile
├── cluster.json
├── config.yaml
├── deconvolution.bsh
├── define_czi.bsh
├── define_output.bsh
├── define_tif_zip.bsh
├── duplicate_transformations.bsh
├── export.bsh
├── export_output.bsh
├── fusion.bsh
├── registration.bsh 
├── timelapse_registration.bsh
├── timelapse_utils.py
├── transform.bsh		
└── xml_merge.bsh			
</pre>
<p><br />
</p>
<ul><li> The  <i>Snakefile</i> contains the name of the processing step as well as the input and output rules for the processing. </li>
<li> <i>config.yaml</i> contains the parameters that configure the beanshell scripts found in the data directory.</li>
<li> <i>cluster.json</i> contains the resource information (processing time, number of cores and memory) for the queuing system. </li>
<li> <i>*.bsh</i> scripts contain the instructions for Fiji to run the processing.</li></ul>
<h2><span class="mw-headline" id="tools_directory">tools directory</span></h2>
<p>The tool directory contains scripts for common file format pre-processing.
Some datasets are currently only usable when resaving them into <i>.tif</i>:
</p>
<ul><li> discontinous <i>.czi</i> datasets</li>
<li> <i>.czi</i> dataset with multiple groups</li>
<li> <i>.ome.tiff</i> files</li></ul>
<p>The <i>master_preprocessing.sh</i> file is the configuration script that contains the information about the dataset that needs to be resaved. In the <i>czi_resave</i> as well as the <i>ometiff_resave</i> directory you will find the the <i>create-resaving-jobs.sh</i> script that creates a job for each time point. The <i>submit-jobs</i> script sends these jobs to the cluster where they call the <i>resaving.bsh</i> or <i>ometiff_resave.bsh</i>  script. The beanshell then uses the Fiji macro and resaves the files. The resaving of <i>.czi</i> files is using LOCI bioformats and preserves the metadata. 
</p>
<pre class="brush:bash">
/path/to/repository/spim_registration/tools/
├── czi_resave/
    ├── create-resaving-jobs.sh
    ├── resaving.bsh
    └── submit-jobs
├── ometiff_resave/
    ├── create-ometiff_resave.sh
    ├── ometiff_resave.bsh
    └── submit-jobs
└──  master_preprocessing.sh
</pre>
<h2><span class="mw-headline" id="cluster_tools_directory">cluster_tools directory</span></h2>
<p>The cluster tools directory contains the libraries for GPU deconvolution and the virtual frame buffer (xvfb) for running Fiji headless. 
</p>
<pre class="brush:bash">
libFourierConvolutionCUDALib.so
xvfb-run
</pre>
<h2><span class="mw-headline" id="sysconfcpus">sysconfcpus</span></h2>
<p>We use <b><a rel="nofollow" class="external text" href="http://www.kev.pulo.com.au/libsysconfcpus/">Libsysconfcpus</a></b> to restrict how many cores Fiji is using on the cluster.
</p><p>Compile with:
</p>
<pre class="brush:bash">
 CFLAGS=-ansi ./configure --prefix=$PREFIX
 make
 make install
</pre>
<p>where PREFIX is the installation directory.
ANSI mode is necessary when compiling with our default GCC version, 4.9.2.
It may or may not be necessary with older versions.
</p>
<h1><span class="mw-headline" id="Command_line">Command line</span></h1>
<p>It is very likely that the cluster computer does not run ANY Graphical User Interface and relies exclusively on the command line. Steering a cluster from the command line is fairly easy - I use about 10 different commands to do everything I need to do. Since the Linux command line may be unfamiliar to most biologists we start a separate <b><a href="Linux_command_line_tutorial" title="Linux command line tutorial">Linux_command_line_tutorial</a></b> and <b><a rel="nofollow" class="external free" href="http://swcarpentry.github.io/shell-novice/">http://swcarpentry.github.io/shell-novice/</a></b> page that explains the bare essentials.
</p>
<h1><span class="mw-headline" id="Initial_setup_of_the_workflow">Initial setup of the workflow</span></h1>
<p>After you cloned the snakemake-workflows repository you need to configure the <i>config.yaml</i> for your setup.
This means you need to specify the directory for your Fiji, the location of the xvfb-run and the location for the GPU deconvolution libraries. 
Go into the timelapse directory of the snakemake-workflows and open the <i>config.yaml</i> with your preferred editor for example nano and change the settings in section <i>7. Software directories</i>:
</p><p><br />
</p>
<pre class="brush:bash">
cd snakemake-workflows/spim_registration/timelapse/
nano config.yaml
</pre>
<pre class="brush:bash">
 # ============================================================================
  # 7. Software directories
  # 
  # Description: paths to software dependencies of processing
  # Options: Fiji location
  #          beanshell and snakefile diretory
  #          directory for cuda libraries
  #          xvfb setting
  #          sysconfcpus setting
  # ============================================================================
  # current working Fiji
  fiji-app: "/sw/users/schmied/packages/2015-06-30_Fiji.app.cuda/ImageJ-linux64",
  # bean shell scripts and Snakefile
  bsh_directory: "/projects/pilot_spim/Christopher/snakemake-workflows/spim_registration/timelapse/",
  # Directory that contains the cuda libraries
  directory_cuda: "/sw/users/schmied/cuda/",
  # xvfb 
  fiji-prefix: "/sw/users/schmied/packages/xvfb-run -a",       # calls xvfb for Fiji headless mode
  sysconfcpus: "sysconfcpus -n",
  memory-prefix: "-Xmx"
</pre>
<p>After this initial setup you can proceed to modify the <i>config.yaml</i> for your specific dataset.
</p>
<h1><span class="mw-headline" id="Setup_for_the_dataset">Setup for the dataset</span></h1>
<p>You can download a 5 view, single channel .czi example dataset here:
</p><p><b><a rel="nofollow" class="external free" href="http://tomancak-srv1.mpi-cbg.de/~schmied/">http://tomancak-srv1.mpi-cbg.de/~schmied/</a></b>
</p><p>The example dataset looks like this:
</p>
<pre class="brush:bash">
/path/to/data/
├── exampleSingleChannel.czi
├── exampleSingleChannel(1).czi
├── exampleSingleChannel(2).czi
├── exampleSingleChannel(3).czi
└── exampleSingleChannel(4).czi
</pre>
<p>For processing, the dataset directory will also contain the config.yaml file for the specific dataset. 
Go to your dataset directory and make a symlink for the config.yaml:
</p>
<pre class="brush:bash">
cd /path/to/data/
ln -s /path/snakemake-workflows/spim_registration/timelapse/config.yaml
</pre>
<p>Now the dataset directory has a symlink for the config.yaml:
</p>
<pre class="brush:bash">
/path/to/data/
├── exampleSingleChannel.czi
├── exampleSingleChannel(1).czi
├── exampleSingleChannel(2).czi
├── exampleSingleChannel(3).czi
├── exampleSingleChannel(4).czi
└── config.yaml	 		# copied/symlinked from this repo
</pre>
<h2><span class="mw-headline" id="config.yaml"><i>config.yaml</i></span></h2>
<p>The entire processing is controlled via the yaml file.
</p><p>he key parameters for the processing are found in the first (common) part of the yaml file.
These parameters are usually dataset and user dependent. The second part contains the advanced and manual overrides for each processing step. These steps correspond to the rules in the snakefile.
</p>
<h2><span class="mw-headline" id="Setting_up_the_config.yaml_file_for_processing">Setting up the <i>config.yaml</i> file for processing</span></h2>
<h3><span class="mw-headline" id="Processing_switches">Processing switches</span></h3>
<p>In the first section you need to decide which processing you want to carry out. 
Open the <i>config.yaml</i> file:
</p>
<pre class="brush:bash">
cd snakemake-workflows/spim_registration/timelapse/
nano config.yaml
</pre>
<p>The <i>transformation_switch</i> switches between normal single channel/ multi channel processing where all channels contain beads for registration and multi channel processing where only one channel contains beads.
If there are channels present without beads the transformations of the other channels need to be copied in order to register them.
</p><p>Set the <i>transformation_switch</i> to <i>timelapse</i> to do single channel processing or multichannel processing where all channels contain beads:
</p>
<pre class="brush:bash">
transformation_switch: "timelapse",
</pre>
<p>Set the <i>transformation_switch</i> to <i>timelapse_duplicate</i> to duplicate the transformation from one channel to others:
</p>
<pre class="brush:bash">
transformation_switch: "timelapse_duplicate",
</pre>
<p>The <i>fusion_switch</i> decides between weighted-average fusion and deconvolution. 
Set the <i>fusion_switch</i> to <i>fusion</i> to do weighted-average fusion:
</p>
<pre class="brush:bash">
fusion_switch: "fusion",
</pre>
<p>Set the <i>fusion_switch</i> to <i>deconvolution</i> to perform deconvolution:
</p>
<pre class="brush:bash">
fusion_switch: "deconvolution",
</pre>
<h3><span class="mw-headline" id="General_Settings">General Settings</span></h3>
<p>In the the next section specify the name of the dataset. This will be the name of the <i>HDF5</i> file and the <i>XML</i> file:
</p>
<pre class="brush:bash">
hdf5_xml_filename: '"dataset_one"',
</pre>
<p>Then specify the number of time points of the dataset. The example dataset has 2 time points.
The processing of each time point runs in parallel on the cluster. 
</p>
<pre class="brush:bash">
ntimepoints: 2,  
</pre>
<p>Then specify the angles, the channels and the illumination side. If you resaved data into <i>.tif</i> from <i>.czi</i> then give the appropriate numbers (i.e. 0,1). 
The values are separated by a comma:
</p>
<pre class="brush:bash">
angles: "0,72,144,216,288",
channels: "green", 
illumination: "0", 
</pre>
<p>If you want to process dual channel datasets use two different names for the channels:
</p>
<pre class="brush:bash">
angles: "0,72,144,216,288",
channels: "green,red", 
illumination: "0", 
</pre>
<h4><span class="mw-headline" id="Settings_for_.czi_files">Settings for .czi files</span></h4>
<p>If you process <i>.czi</i> files then give the name of the first <i>.czi</i> (file without index): 
</p>
<pre class="brush:bash">
first_czi: "exampleSingleChannel.czi",
</pre>
<h4><span class="mw-headline" id="Settings_for_.tif_datasets">Settings for .tif datasets</span></h4>
<p>For processing of <i>.tif</i> files give the pattern of the files and if you process single channel datasets or dual channel datasets:
</p>
<pre class="brush:bash">
image_file_pattern: 'img_TL{{t}}_Angle{{a}}.tif',
multiple_channels: '"NO (one channel)"', 
</pre>
<p>For datasets with multiple channels the files can be separated by channel or each file can contain both channels. 
For multi channel datasets with separated files per channel give additionally the channel information of the <i>image_file_pattern</i>
</p>
<pre class="brush:bash">
image_file_pattern: 'img_TL{{t}}_Angle{{a}}_Channels{{c}}.tif',
multiple_channels: '"YES (one file per channel)"', 
</pre>
<p>If the files contain both channels then leave out the channel information in the <i>image_file_pattern</i>. 
And specify for <i>multiple_channels</i> that you want to process multi channel datasets:
</p>
<pre class="brush:bash">
image_file_pattern: 'img_TL{{t}}_Angle{{a}}.tif',
multiple_channels: '"YES (all channels in one file)"', 
</pre>
<h3><span class="mw-headline" id="Detection_and_registration">Detection and registration</span></h3>
<p>To carry out the registration specify the channels for the data containing beads. For single channel data and multi channel data where all channels contain beads for registration you want to select the following: As interest points specify '"beads"'. For multi channel datasets indicate '"beads,beads"':
</p>
<pre class="brush:bash">
reg_process_channel: '"All channels"',
reg_interest_points_channel: '"beads"',
</pre>
<p>If you have dual channel datasets where only one channel contains beads specify that you want to select only one channel. Also specify the source and target channels. And specify the correct channel that should not be registered:
</p>
<pre class="brush:bash">
reg_process_channel: '"All channels"',
source_channel: "red",
target_channel: "green",
reg_interest_points_channel: '"[DO NOT register this channel],beads"',
</pre>
<p>Next give the parameters for the detection method. Select the method which is used for registration (i.e. Difference-of-Mean or Difference-of-Gaussian).
We recommend using Difference-of-Gaussian. Give the information for radius 1 and 2 as well as the threshold that you retrieved by processing the reference time point with the Graphical user interface:
</p>
<pre class="brush:bash">
type_of_detection: '"Difference-of-Gaussian"',
sigma: '1.3',
reg_threshold: '0.005',
</pre>
<p>For Difference-of-Mean registration specify radius_1, radius_2 and the threshold:
</p>
<pre class="brush:bash">
type_of_detection: '"Difference-of-Gaussian"',
reg_radius_1: '2',
reg_radius_2: '3',
reg_threshold: '0.005',
</pre>
<h3><span class="mw-headline" id="Timelapse_registration">Timelapse registration</span></h3>
<p>Specify which time point should be used as reference time point.
We generally use a time point in the middle of the dataset:
</p>
<pre class="brush:bash">
reference_timepoint: '1', 
</pre>
<h3><span class="mw-headline" id="Weighted-average_fusion">Weighted-average fusion</span></h3>
<p>For the weighted-average fusion specify the downsampling factor and the bounding box determined in the GUI processing on the reference time point.
The bounding box is for the Weighted-average fusion independent of the downsampling:
</p>
<pre class="brush:bash">
downsample: '1', 
minimal_x: '274',
minimal_y: '17',
minimal_z: '-423',
maximal_x: '1055',
maximal_y: '1928',
maximal_z: '480',
</pre>
<h3><span class="mw-headline" id="Multiview_deconvolution">Multiview deconvolution</span></h3>
<h4><span class="mw-headline" id="External_transformation">External transformation</span></h4>
<p>If you want to use downsampling for the multiview deconvolution set the <i>external_trafo_switch</i> to <i>external_trafo</i>.
Without downsampling use <i>_transform</i>. The matrix for the external transformation specifies the downsampling.
Here it is set to 2x downsampling:
</p>
<pre class="brush:bash">
external_trafo_switch: "external_trafo",
matrix_transform: '"0.5, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0"',
</pre>
<h4><span class="mw-headline" id="Deconvolution_settings">Deconvolution settings</span></h4>
<p>To carry out the deconvolution specify the numbers of iterations as well as the bounding box. For the multiview deconvolution the bounding box needs to take the downsampling into account: 
</p>
<pre class="brush:bash">
iterations: '15',
minimal_x_deco: '137',
minimal_y_deco: '-8',
minimal_z_deco: '-211',
maximal_x_deco: '527',
maximal_y_deco: '964',
maximal_z_deco: '240',
</pre>
<p>Then specify the source for the point-spread-function (PSF). For single channel datasets it is just '"beads"'.
</p>
<pre class="brush:bash">
detections_to_extract_psf_for_channel: '"beads"',
</pre>
<p>For dual channel datasets its '"beads,beads"'
</p>
<pre class="brush:bash">
detections_to_extract_psf_for_channel: '"beads,beads"',
</pre>
<p>If you process multi channel datasets where only one channel contains beads then specify which channel does not contain beads:
</p>
<pre class="brush:bash">
detections_to_extract_psf_for_channel: '"[Same PSF as channel red],beads"',
</pre>
<h3><span class="mw-headline" id="Software_directories">Software directories</span></h3>
<p>Here the directories for the Fiji, <i>beanshell</i> scripts, CUDA libraries and xvfb are stored.
Also the prefix for sysconfcpus and the memory prefix for Fiji are stored:
</p>
<pre class="brush:bash">
  # current working Fiji
  fiji-app: "/sw/users/schmied/packages/2015-06-30_Fiji.app.cuda/ImageJ-linux64",
  # bean shell scripts and Snakefile
  bsh_directory: "/projects/pilot_spim/Christopher/snakemake-workflows/spim_registration/timelapse/",
  # Directory that contains the cuda libraries
  directory_cuda: "/sw/users/schmied/cuda/",
  # xvfb 
  fiji-prefix: "/sw/users/schmied/packages/xvfb-run -a",       # calls xvfb for Fiji headless mode
  sysconfcpus: "sysconfcpus -n",
  memory-prefix: "-Xmx"
</pre>
<h3><span class="mw-headline" id="Fiji_Resource_settings">Fiji Resource settings</span></h3>
<p>Here the resource restrictions for Fiji with the number of cores and memory are specified for each processing step.
These settings need to match the cluster.json file:
</p>
<pre class="brush:bash">
Fiji_resources: {
  # setting for hdf5 resave:
  num_cores_hdf5: 3,
  mem_hdf5: "20g",
  # setting for registration:
  num_cores_reg: 4,
  mem_reg: "40g",
  # setting for timelapse registration:
  num_cores_time: 3,
  mem_time: "50g",
  # settings for average fusion:
  num_cores_fusion: 6,
  mem_fusion: "50g",
  # settings for deconvolution:
  num_cores_deco: 12,
  mem_deco: "110g",
  # settings for resaving of output:
  num_cores_output: 3,
  mem_output: "20g"
</pre>
<h3><span class="mw-headline" id="Advanced_settings">Advanced settings</span></h3>
<p>In the advanced settings are more options for further refining the processing. 
These settings should only be changed when necessary.
</p>
<h2><span class="mw-headline" id="cluster.json"><i>cluster.json</i></span></h2>
<p>The <i>cluster.json</i> contains the resource information for the queuing system. It should match the Fiji resource settings. 
</p>
<pre class="brush:bash">
{
    "__default__"&#160;:
    {
	"lsf_extra"&#160;: "-R \"span[hosts=1]\"",
	"lsf_q"&#160;: "short"	
    },
    
    "hdf5_xml"&#160;:
    {
 	"lsf_extra"&#160;: "-n 3 -R \"span[hosts=1] rusage[mem=20000]\""
    },

    "resave_hdf5"&#160;:	
    {
 	"lsf_extra"&#160;: "-n 3 -R \"span[hosts=1] rusage[mem=20000]\""
    },

    "registration"&#160;:
    {
        "lsf_extra"&#160;: "-n 4 -R \"span[hosts=1] rusage[mem=40000]\""
    },
    
    "timelapse"&#160;: 
    {
    	"lsf_extra"&#160;: "-n 6 -R \"span[hosts=1] rusage[mem=50000]\""
    },

    "external_transfrom"&#160;:
    {
        "lsf_extra"&#160;: "-R \"span[hosts=1] rusage[mem=10000]\""
    },

    "fusion"&#160;: 
    {
        "lsf_extra"&#160;: "-n 6 -R \"span[hosts=1] rusage[mem=50000]\"",
        "lsf_q"&#160;: "short"
    },

    "deconvolution"&#160;:
    {
        "lsf_extra"&#160;: "-n 12 -R \"span[hosts=1] rusage[mem=110000]\"",
	"lsf_q"&#160;: "gpu"
    },
    
    "resave_hdf5_output"&#160;:
    {
	"lsf_extra"&#160;: "-n 3 -R \"span[hosts=1] rusage[mem=20000]\""
    }
}
</pre>
<h2><span class="mw-headline" id="Submitting_Jobs">Submitting Jobs</span></h2>
<p>We recommend to execute Snakemake within  <b><a rel="nofollow" class="external text" href="https://www.gnu.org/software/screen/manual/screen.html">screen</a></b>. 
To execute Snakemake you need to call Snakemake, specify the number of jobs, the location of the data and to dispatch jobs to a cluster with the information for the queuing system. Here is a list of commands and flags that are used for the Snakemake workflow:
</p><p>Local back end:
/path/to/snakemake/snakemake -j 1 -d /path/to/data/
</p><p>Flag for number of jobs run in parallel:
-j &lt;number of jobs&gt;
</p><p>Flag for specifying data location:
-d /path/to/data/
</p><p>Flag for dry run of snakemake:
-n
</p><p>Force the execution of a rule:
-R &lt;name of rule&gt;
</p><p>For DRMAA back end add: 
--drmaa " -q {cluster.lsf_q} {cluster.lsf_extra}"
</p><p>For Lsf backend add:
--cluster "bsub -q {cluster.lsf_q} {cluster.lsf_extra}”
</p><p>To specify the configuration script for the queuing system:
--cluster-config ./cluster.json
</p><p>To save error and output files of cluster add:
--drmaa " -q {cluster.lsf_q} {cluster.lsf_extra} -o test.out -e test.err"
--cluster "bsub -q {cluster.lsf_q} {cluster.lsf_extra} -o test.out -e test.err“
</p><p><br />
The commands to execute snakemake would then look like this:
</p><p>If DRMAA is supported on your cluster:
</p>
<pre class="brush:bash">
/path/to/snakemake/snakemake -j 2 -d /path/to/data/ --cluster-config ./cluster.json --drmaa " -q {cluster.lsf_q} {cluster.lsf_extra}"
</pre>
<p>If not:
</p>
<pre class="brush:bash">
/path/to/snakemake/snakemake -j 2 -d /path/to/data/ --cluster-config ./cluster.json --cluster "bsub -q {cluster.lsf_q} {cluster.lsf_extra}"
</pre>
<p>For error and output of the cluster add -o test.out -e test.err e.g.:
</p><p>DRMAA
</p>
<pre class="brush:bash">
/path/to/snakemake/snakemake -j 2 -d /path/to/data/ --cluster-config ./cluster.json --drmaa " -q {cluster.lsf_q} {cluster.lsf_extra} -o test.out -e test.err"
</pre>
<p>LSF
</p>
<pre class="brush:bash">
/path/to/snakemake/snakemake -j 2 -d /path/to/data/ --cluster-config ./cluster.json --cluster "bsub -q {cluster.lsf_q} {cluster.lsf_extra} -o test.out -e test.err"
</pre>
<p>Note:  the error and output of the cluster of all jobs are written into these files.
</p>
<h2><span class="mw-headline" id="Log_files_and_supervision_of_the_pipeline">Log files and supervision of the pipeline</span></h2>
<p>The log files are written into a new directory in the data directory called "logs".
The log files are ordered according to their position in the workflow. Multiple or alternative steps in the pipeline are indicated by numbers. 
</p><p>force certain rules:
use the -R flag to rerun a particular rule and everything downstream
-R &lt;name of rule&gt;
</p>
<h1><span class="mw-headline" id="Cluster">Cluster</span></h1>
<p>Every cluster is different both in terms of the used hardware and the software running on it, particularly the scheduling system. Here we use a cluster computer at the MPI-CBG that consists of <b>44</b> nodes each with <b>12</b> Intel Xeon E5-2640 cores running @ 2.50 GHz and enjoying <b>128GB</b> of memory. The cluster nodes have access to 200TB of data storage provided by a dedicated Lustre distributed file system, suffice to say that it is optimised for high performance input/output (read/write) operations which is crucial for the SPIM data volumes.
</p><p>Each node of this cluster runs CentOS 6.3 Linux distribution. The queuing system running on the MPI-CBG cluster is LSF. The basic principles of job submission are the same across queuing systems, but the exact syntax will of course differ.
</p>
<!-- 
NewPP limit report
Cached time: 20200713064536
Cache expiry: 86400
Dynamic content: false
CPU time usage: 0.028 seconds
Real time usage: 0.029 seconds
Preprocessor visited node count: 568/1000000
Preprocessor generated node count: 1479/1000000
Post‐expand include size: 1279/2097152 bytes
Template argument size: 786/2097152 bytes
Highest expansion depth: 3/40
Expensive parser function count: 0/3
-->

<!-- 
Transclusion expansion time report (%,ms,calls,template)
100.00%    4.599      1 - Template:Infobox
100.00%    4.599      1 - -total
-->
</div><div class="printfooter">
Retrieved from "<a dir="ltr" href="index.php?title=Automated_workflow_for_parallel_Multiview_Reconstruction&amp;oldid=19613">http://imagej.net/index.php?title=Automated_workflow_for_parallel_Multiview_Reconstruction&amp;oldid=19613</a>"</div>
							</div>

			<div id="footer">
				<p> This page was last modified on 10 March 2016, at 15:13.</p><ul><li><a href="./ImageJ:Privacy_policy" title="ImageJ:Privacy policy">Privacy policy</a></li><li><a href="./ImageJ:About" class="mw-redirect" title="ImageJ:About">About ImageJ</a></li><li><a href="Imprint" title="Imprint">Imprint</a></li></ul>			</div>

			<div id="catlinks" class="catlinks" data-mw="interface"><div id="mw-normal-catlinks" class="mw-normal-catlinks"><a href="./Special:Categories" title="Special:Categories">Categories</a>: <ul><li><a href="./Category:Transform" title="Category:Transform">Transform</a></li><li><a href="./Category:Registration" title="Category:Registration">Registration</a></li><li><a href="./Category:Deconvolution" title="Category:Deconvolution">Deconvolution</a></li></ul></div></div>		</div>

		<div id="bottom-wrap">
			<div id="footer-wrap-inner">
				<div id="ternary" class="footer">
					<ul>
						<li class="widget">
							<img id="logo" src="skins/imagej-128.png" alt="">
						</li>
					</ul>
				</div>
			</div>
		</div>
		<script>(window.RLQ=window.RLQ||[]).push(function(){mw.loader.load(["ext.fancytree","ext.suckerfish","mediawiki.toc","mediawiki.action.view.postEdit","site","mediawiki.user","mediawiki.hidpi","mediawiki.page.ready","mediawiki.searchSuggest","ext.SimpleTooltip"]);});</script><script>(window.RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgBackendResponseTime":265});});</script>
		</body>
		</html>
		