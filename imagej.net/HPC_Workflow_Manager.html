<!DOCTYPE html>
<html class="client-nojs" lang="en" dir="ltr">
<head>
<meta charset="UTF-8"/>
<title>HPC Workflow Manager - ImageJ</title>
<script>document.documentElement.className = document.documentElement.className.replace( /(^|\s)client-nojs(\s|$)/, "$1client-js$2" );</script>
<script>(window.RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgCanonicalNamespace":"","wgCanonicalSpecialPageName":false,"wgNamespaceNumber":0,"wgPageName":"HPC_Workflow_Manager","wgTitle":"HPC Workflow Manager","wgCurRevisionId":45684,"wgRevisionId":45684,"wgArticleId":10991,"wgIsArticle":true,"wgIsRedirect":false,"wgAction":"view","wgUserName":null,"wgUserGroups":["*"],"wgCategories":[],"wgBreakFrames":false,"wgPageContentLanguage":"en","wgPageContentModel":"wikitext","wgSeparatorTransformTable":["",""],"wgDigitTransformTable":["",""],"wgDefaultDateFormat":"dmy","wgMonthNames":["","January","February","March","April","May","June","July","August","September","October","November","December"],"wgMonthNamesShort":["","Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec"],"wgRelevantPageName":"HPC_Workflow_Manager","wgRelevantArticleId":10991,"wgRequestId":"0f320732e2b09e945fc13e0f","wgIsProbablyEditable":false,"wgRestrictionEdit":[],"wgRestrictionMove":[],"wgPreferredVariant":"en","fancytree_path":"/extensions/TreeAndMenu/fancytree"});mw.loader.state({"site.styles":"ready","noscript":"ready","user.styles":"ready","user.cssprefs":"ready","user":"ready","user.options":"loading","user.tokens":"loading","mediawiki.legacy.shared":"ready","mediawiki.legacy.commonPrint":"ready","mediawiki.sectionAnchor":"ready","skins.erudite":"ready"});mw.loader.implement("user.options@0j3lz3q",function($,jQuery,require,module){mw.user.options.set({"variant":"en"});});mw.loader.implement("user.tokens@1ku9xth",function ( $, jQuery, require, module ) {
mw.user.tokens.set({"editToken":"+\\","patrolToken":"+\\","watchToken":"+\\","csrfToken":"+\\"});/*@nomin*/;

});mw.loader.load(["mediawiki.page.startup"]);});</script>
<link rel="stylesheet" href="load.php%3Fdebug=false&amp;lang=en&amp;modules=mediawiki.legacy.commonPrint%252Cshared%257Cmediawiki.sectionAnchor%257Cskins.erudite&amp;only=styles&amp;skin=erudite.css"/>
<script async="" src="load.php%3Fdebug=false&amp;lang=en&amp;modules=startup&amp;only=scripts&amp;skin=erudite"></script>
<link rel="stylesheet" href="extensions/TreeAndMenu/fancytree/fancytree.css"/><link rel="stylesheet" href="extensions/TreeAndMenu/suckerfish/suckerfish.css"/>
<meta name="ResourceLoaderDynamicStyles" content=""/>
<link rel="stylesheet" href="load.php%3Fdebug=false&amp;lang=en&amp;modules=site.styles&amp;only=styles&amp;skin=erudite.css"/>
<meta name="generator" content="MediaWiki 1.28.0"/>
<meta name="description" content="HPC Workflow Manager is a Fiji plugin, it enables users to parallelize Macro scripts, define tasks, report the progress of the tasks, upload data to the remote cluster, monitor computation progress, and examine and download the results via their local Fiji installation."/>
<link rel="shortcut icon" href="skins/ij2.ico"/>

<script type="text/javascript" src="extensions/SyntaxHighlighter/syntaxhighlighter/scripts/shCore.js"></script>
<script type="text/javascript" src="extensions/SyntaxHighlighter/syntaxhighlighter/scripts/shBrushJava.js"></script>
<script type="text/javascript" src="extensions/SyntaxHighlighter/syntaxhighlighter/scripts/shBrushPlain.js"></script>
<script type="text/javascript">
SyntaxHighlighter.all();
</script>
<link rel="stylesheet" type="text/css" media="screen" href="extensions/SyntaxHighlighter/syntaxhighlighter/styles/shCoreMinit.css" />

	<meta property="og:type" content="article"/>

	<meta property="og:site_name" content="ImageJ"/>

	<meta property="og:title" content="HPC Workflow Manager"/>

	<meta property="og:description" content="HPC Workflow Manager is a Fiji plugin, it enables users to parallelize Macro scripts, define tasks, report the progress of the tasks, upload data to the remote cluster, monitor computation progress, and examine and download the results via their local Fiji installation."/>


<meta name="viewport" content="width=device-width, initial-scale=1" />
</head>
<body class="mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject page-HPC_Workflow_Manager rootpage-HPC_Workflow_Manager skin-erudite action-view">
		<div class="mw-jump">
			<a href="HPC_Workflow_Manager.html#bodyContent">Skip to content</a>, 			<a href="HPC_Workflow_Manager.html#search">Skip to search</a>
		</div>

		<div id="top-wrap" role="banner">
			<h1><a href="Welcome" title="ImageJ" rel="home">ImageJ</a></h1>
			<div id="tagline">From ImageJ</div>

			<a id="menubutton" href="HPC_Workflow_Manager.html#menu">Menu</a>
			<div id="nav" role="navigation">
			<ul id='menu'>
<li id="menu-item-n-About"><a href="ImageJ">About</a></li>
<li id="menu-item-n-Downloads"><a href="Downloads">Downloads</a></li>
<li id="menu-item-n-Learn"><a href="Learn">Learn</a></li>
<li id="menu-item-n-Develop"><a href="Development">Develop</a></li>
<li id="menu-item-n-News"><a href="News">News</a></li>
<li id="menu-item-n-Events"><a href="Events">Events</a></li>
<li id="menu-item-n-Help"><a href="Help">Help</a></li>
</ul>
			</div>
		</div>

		<div id="mw-js-message"></div>
		
		<div id="main" role="main">

			<div id="bodyContent">
				<h1>HPC Workflow Manager</h1>
				
				<div id="mw-content-text" lang="en" dir="ltr" class="mw-content-ltr"><div id="toc" class="toc"><div id="toctitle"><h2>Contents</h2></div>
<ul>
<li class="toclevel-1 tocsection-1"><a href="HPC_Workflow_Manager.html#General_information"><span class="tocnumber">1</span> <span class="toctext">General information</span></a>
<ul>
<li class="toclevel-2 tocsection-2"><a href="HPC_Workflow_Manager.html#What_is_HPC_Workflow_Manager"><span class="tocnumber">1.1</span> <span class="toctext">What is HPC Workflow Manager</span></a></li>
<li class="toclevel-2 tocsection-3"><a href="HPC_Workflow_Manager.html#Why_use_HPC_Workflow_Manager"><span class="tocnumber">1.2</span> <span class="toctext">Why use HPC Workflow Manager</span></a></li>
<li class="toclevel-2 tocsection-4"><a href="HPC_Workflow_Manager.html#Workflow_types"><span class="tocnumber">1.3</span> <span class="toctext">Workflow types</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-5"><a href="HPC_Workflow_Manager.html#How_to_use"><span class="tocnumber">2</span> <span class="toctext">How to use</span></a>
<ul>
<li class="toclevel-2 tocsection-6"><a href="HPC_Workflow_Manager.html#How_to_start_the_plugin"><span class="tocnumber">2.1</span> <span class="toctext">How to start the plugin</span></a></li>
<li class="toclevel-2 tocsection-7"><a href="HPC_Workflow_Manager.html#How_to_login"><span class="tocnumber">2.2</span> <span class="toctext">How to login</span></a></li>
<li class="toclevel-2 tocsection-8"><a href="HPC_Workflow_Manager.html#How_to_create_a_new_job"><span class="tocnumber">2.3</span> <span class="toctext">How to create a new job</span></a></li>
<li class="toclevel-2 tocsection-9"><a href="HPC_Workflow_Manager.html#How_to_upload_the_data_and_the_Macro_script"><span class="tocnumber">2.4</span> <span class="toctext">How to upload the data and the Macro script</span></a></li>
<li class="toclevel-2 tocsection-10"><a href="HPC_Workflow_Manager.html#How_to_start_a_job"><span class="tocnumber">2.5</span> <span class="toctext">How to start a job</span></a></li>
<li class="toclevel-2 tocsection-11"><a href="HPC_Workflow_Manager.html#Inspecting_progress"><span class="tocnumber">2.6</span> <span class="toctext">Inspecting progress</span></a></li>
<li class="toclevel-2 tocsection-12"><a href="HPC_Workflow_Manager.html#Job_dashboard"><span class="tocnumber">2.7</span> <span class="toctext">Job dashboard</span></a></li>
<li class="toclevel-2 tocsection-13"><a href="HPC_Workflow_Manager.html#How_to_download_the_results"><span class="tocnumber">2.8</span> <span class="toctext">How to download the results</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-14"><a href="HPC_Workflow_Manager.html#How_to_write_a_parallel_Macro"><span class="tocnumber">3</span> <span class="toctext">How to write a parallel Macro</span></a>
<ul>
<li class="toclevel-2 tocsection-15"><a href="HPC_Workflow_Manager.html#Prerequisites"><span class="tocnumber">3.1</span> <span class="toctext">Prerequisites</span></a></li>
<li class="toclevel-2 tocsection-16"><a href="HPC_Workflow_Manager.html#How_to_use_parallelization_function_.28by_example.29"><span class="tocnumber">3.2</span> <span class="toctext">How to use parallelization function (by example)</span></a>
<ul>
<li class="toclevel-3 tocsection-17"><a href="HPC_Workflow_Manager.html#Simple_greeting_example"><span class="tocnumber">3.2.1</span> <span class="toctext">Simple greeting example</span></a></li>
</ul>
</li>
<li class="toclevel-2 tocsection-18"><a href="HPC_Workflow_Manager.html#How_to_use_the_progress_reporting_functions_.28by_example.29"><span class="tocnumber">3.3</span> <span class="toctext">How to use the progress reporting functions (by example)</span></a>
<ul>
<li class="toclevel-3 tocsection-19"><a href="HPC_Workflow_Manager.html#Expanding_on_the_greeting_example"><span class="tocnumber">3.3.1</span> <span class="toctext">Expanding on the greeting example</span></a></li>
</ul>
</li>
<li class="toclevel-2 tocsection-20"><a href="HPC_Workflow_Manager.html#Available_functions_.28list.29"><span class="tocnumber">3.4</span> <span class="toctext">Available functions (list)</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-21"><a href="HPC_Workflow_Manager.html#Installation"><span class="tocnumber">4</span> <span class="toctext">Installation</span></a>
<ul>
<li class="toclevel-2 tocsection-22"><a href="HPC_Workflow_Manager.html#Instructions"><span class="tocnumber">4.1</span> <span class="toctext">Instructions</span></a></li>
</ul>
</li>
</ul>
</div>

<h2><span class="mw-headline" id="General_information">General information</span></h2>
<h3><span class="mw-headline" id="What_is_HPC_Workflow_Manager">What is HPC Workflow Manager</span></h3>
<p>HPC Workflow Manager is a Fiji plugin, it enables users to parallelize Macro scripts, define tasks, report the progress of the tasks, upload data to the remote cluster, monitor computation progress, and examine and download the results via their local Fiji installation.
</p><p>HPC Workflow Manager is developed at IT4Innovations, Ostrava, Czech Republic.
</p>
<h3><span class="mw-headline" id="Why_use_HPC_Workflow_Manager">Why use HPC Workflow Manager</span></h3>
<p><i>"Today, parallel processing solves some of our biggest problems in much the same way that settlers of the Old West solved their biggest problems using parallel oxen. If they were using an ox to move a tree and the ox was not big enough or strong enough, they certainly didn’t try to grow a bigger ox—they used two oxen. If our computer isn’t fast enough or powerful enough, instead of trying to develop a faster, more powerful computer, why not simply use multiple computers?"</i>
-Essentials of Computer Organization and Architecture, 5th Edition by Null
</p><p>The end of major serial execution performance gains due to limitations in Moore's law means that it is no longer possible to solve problems with big datasets and/or computational requirements just by getting a newer processor and hopping that the existing serial programs will perform better. Instead, more processors in parallel must be used. Personal computers have been moving in this direction for many years by adding multiple cores, accelerating performance through the use of GPUs, bringing memory closer to the CPU, etc. Still, there are massive datasets that require even more performance. Such performance can only be found today in supercomputers.
</p><p>Life scientists are one category of users that can truly benefit from such a stratospheric amount of performance.
</p><p>Access to supercomputers can often be difficult to get. HPC Workflow Manager aims to reduce the difficulty of obtaining access for the individual user and provide an integrated to Fiji via plugin way which is easy to use through its graphical user interface method for users to add parallelization support to existing Macro scripts.
</p>
<h3><span class="mw-headline" id="Workflow_types">Workflow types</span></h3>
<p>The HPC Workflow Manager Client supports two workflow types:
</p>
<ul><li> SPIM; and</li>
<li> Macro.</li></ul>
<p>This guide will only explain how to use the newly added Macro workflow type.
</p><p>If you are interested in the SPIM workflow type visit <a rel="nofollow" class="external text" href="SPIM_Workflow_Manager_For_HPC">this</a> page.
</p>
<h2><span class="mw-headline" id="How_to_use">How to use</span></h2>
<h3><span class="mw-headline" id="How_to_start_the_plugin">How to start the plugin</span></h3>
<p>From the Fiji menu bar select Plugins &gt; Multiview Reconstruction &gt; HPC Workflow Manager and fill in the Login dialog that will appear. For example, see the filled-in dialog in Figure 1.
</p><p><br />
</p>
<div class="thumb tright"><div class="thumbinner" style="width:414px;"><div class="MediaTransformError" style="width: 412px; height: 0px; display:inline-block;">Error creating thumbnail: Unable to save thumbnail to destination</div>  <div class="thumbcaption"><div class="magnify"><a href="./File:Hpc-workflow-manager-login.png" class="internal" title="Enlarge"></a></div>Figure 1: Example of a filled in login dialog.</div></div></div>
<h3><span class="mw-headline" id="How_to_login">How to login</span></h3>
<p>You need to enter the username, password, and email for your account. If it is the first time you use this installation of the plugin you must create a new directory anywhere to use as a working directory. If you have used HPC Workflow Manager in the past you can use an already existing working directory. Select the working directory by clicking on the browse button or typing the path. The directory must already exist.
</p><p>Press "Ok" and the dialog should disappear, and a progress dialog should appear. If not, then a new message should inform you of the error made during filling in the dialog. Correct the error and try again.
</p>
<h3><span class="mw-headline" id="How_to_create_a_new_job">How to create a new job</span></h3>
<p>After the connection to the HPC Cluster is made and the jobs are downloaded from the cluster you should see a window like the one in Figure 2. If it is the first time you run this plugin the table will be empty.
</p>
<div class="center"><div class="thumb tnone"><div class="thumbinner" style="width:502px;"><a href="./File:Hpc-workflow-manager-main-empty.png" class="image"><img alt="" src="_images/b/b3/Hpc-workflow-manager-main-empty.png" width="500" height="112" class="thumbimage" /></a>  <div class="thumbcaption"><div class="magnify"><a href="./File:Hpc-workflow-manager-main-empty.png" class="internal" title="Enlarge"></a></div>Figure 2: Example of the main window of the HPC Workflow Manager, it displays all jobs ever submitted by the user, in this case, it is empty as it is the first time the plugin is used.</div></div></div></div>
<p>Right-click in the empty table or an empty row of the table to display the context menu, an example of the context menu is featured in Figure 3.
</p>
<div class="thumb tright"><div class="thumbinner" style="width:158px;"><div class="MediaTransformError" style="width: 156px; height: 0px; display:inline-block;">Error creating thumbnail: Unable to save thumbnail to destination</div>  <div class="thumbcaption"><div class="magnify"><a href="./File:Hpc_workflow_manager_context_menu.png" class="internal" title="Enlarge"></a></div>Figure 3: Context menu press right click on an empty row or empty table to display.</div></div></div>
<p>Select the first option “Create a new job”. The “Create job” window will appear. From the “Workflow Type” section, select the “Macro Execution” option.
</p><p>In the input data location, you must provide a directory that contains your Macro script (the script must be named “user.ijm”). If this is the first time you are using the HPC Workflow plugin with Macro support, you can use the example found <a rel="nofollow" class="external text" href="https://github.com/MKrumnikl/Ij1MPIWrapper/tree/master/src/main/resources/ExampleScripts/HelloWorld">here</a>.
</p><p>In the node configuration, select four nodes (4) by pressing the up arrow in the spinner four times.
</p><p>In the “Output data location” section leave the default option, “Job subdirectory”, selected.
</p><p>Now, the filled-in form should look like Figure 4. If you are using Linux save the “HelloWorld” example script in your home directory (“~/HelloWorld/user.ijm”) and use that path instead of “C:/Documents/HelloWorld”.
When you are sure that the form is filled-in correctly press the “Create” button.
</p>
<div class="center"><div class="thumb tnone"><div class="thumbinner" style="width:302px;"><a href="./File:Hpc-workflow-manager-create-job.png" class="image"><img alt="" src="_images/c/c7/Hpc-workflow-manager-create-job.png" width="300" height="322" class="thumbimage" /></a>  <div class="thumbcaption"><div class="magnify"><a href="./File:Hpc-workflow-manager-create-job.png" class="internal" title="Enlarge"></a></div>Figure 4: Example of a new Macro job configuration.</div></div></div></div>
<h3><span class="mw-headline" id="How_to_upload_the_data_and_the_Macro_script">How to upload the data and the Macro script</span></h3>
<p>If you have created a new job, the main window should look roughly like Figure 5.
</p>
<div class="center"><div class="thumb tnone"><div class="thumbinner" style="width:302px;"><a href="./File:Hpc-workflow-manager-created-job.png" class="image"><img alt="" src="_images/f/f9/Hpc-workflow-manager-created-job.png" width="300" height="100" class="thumbimage" /></a>  <div class="thumbcaption"><div class="magnify"><a href="./File:Hpc-workflow-manager-created-job.png" class="internal" title="Enlarge"></a></div>Figure 5: A new Macro job has been created.</div></div></div></div>
<p>Before you can start the job, you need to upload your script (“user.ijm”). To do this you must select the “Upload data” item from the context menu. If your script also needs data, they should also be located in the same directory that the user's script is in. The data will be uploaded along with the Macro script file.
</p><p>A timer will appear in the download column. When it has completed uploading the data and user's script the cell that corresponds to the job should indicate that it is “Done” (Figure 6).
</p>
<div class="center"><div class="thumb tnone"><div class="thumbinner" style="width:302px;"><a href="./File:Hpc-workflow-manager-upload-job.png" class="image"><img alt="" src="_images/c/cb/Hpc-workflow-manager-upload-job.png" width="300" height="100" class="thumbimage" /></a>  <div class="thumbcaption"><div class="magnify"><a href="./File:Hpc-workflow-manager-upload-job.png" class="internal" title="Enlarge"></a></div>Figure 6: Uploading files (in this case just the user’s script) is done.</div></div></div></div>
<p>Now that the script file is uploaded the job can be started.
</p>
<h3><span class="mw-headline" id="How_to_start_a_job">How to start a job</span></h3>
<p>Let's inspect figure 6 closer. In the figure you can see the following columns:
</p>
<ul><li> “Job ID” - Job’s identification number;</li>
<li> “Status” – The job’s current status which can be:
<ul><li> “Unknown” – the state of the job is not known;</li>
<li> “Configuring” – the job is being configured;</li>
<li> “Queued” – the job is in a queue and when there are available nodes it will be executed;</li>
<li> “Running” – the job was executed and it is currently running;</li>
<li> “Finished” – the job has stopped running successfully, completing its tasks;</li>
<li> “Failed” – the job has stopped running unsuccessfully, it did not complete its tasks;</li>
<li> “Canceled” – the job was stopped by the user; and</li>
<li> Disposed – the job was disposed.</li></ul></li>
<li> “Creation time” – the time when the job was created.</li>
<li> “Start time” – the time when the job was last started.</li>
<li> “End time” – the time when the job last ended.</li>
<li> “Upload” – whether the job was uploaded.</li>
<li> “Download” – whether the job was downloaded.</li>
<li> “Workflow Type”- whether it is SPIM or Macro workflow type.</li></ul>
<p>Right-click on the new job to display the context menu (of Figure 3). You will notice that there are new enabled items.
</p><p>Right-click the row of the job and select “Start Job” from the context menu.
</p><p>To make the source code of the user cleaner and easier to understand the special functions that make parallelism available to the user are appended to the user script on upload and a new file is created called “parallelMacroWrappedScript.ijm” which is the file that will be executed on the cluster.
</p><p>To inspect the submitted file (for example for debugging) you can right-click the job and select “Open Macro in editor” where you can see the contents of the user script along with the appended function definitions that provide parallelism.
</p><p>Finally, to start the job, right-click on the job and select the “Start job” item from the context menu.
</p>
<h3><span class="mw-headline" id="Inspecting_progress">Inspecting progress</span></h3>
<p>There are two ways to inspect the progress of a job.
</p><p>The first one is by looking at the “Status” of a job. This way you can see whether a job is running on the HPC Cluster or not. In the case of Figure 7, the job is “Queued”.
</p>
<div class="center"><div class="thumb tnone"><div class="thumbinner" style="width:302px;"><a href="./File:Hpc-workflow-manager-queued-job.png" class="image"><img alt="" src="_images/8/8f/Hpc-workflow-manager-queued-job.png" width="300" height="100" class="thumbimage" /></a>  <div class="thumbcaption"><div class="magnify"><a href="./File:Hpc-workflow-manager-queued-job.png" class="internal" title="Enlarge"></a></div>Figure 7: Job is queued.</div></div></div></div>
<p>However, this is a very coarse-grained way to see the progress of the job and when it starts running it does not provide any useful information until it has ended (“Finished”, “Failed” etc.).
</p><p>The second way is to open the “Job dashboard” for the desired job by either double-clicking the job’s row or right-click and select the “Job dashboard” context menu item. Note that the job must be in the state “Running” for this functionality to work, you may open the window earlier and it will start displaying the progress when the state changes automatically.
</p><p>Select the tab “Macro Progress” and ignore the rest of the tabs for now (see section Job dashboard for descriptions of the rest of the tabs).
</p><p>To view the progress, click on the “Macro Progress” if it is not already selected (it should be selected by default). Please be patient while the progress is loading. There is a status bar on the lower right corner of the window where you can monitor the process of getting the progress from the HPC Cluster (the progress is stored in a separate progress file for each compute-node of the HPC Cluster it is run on).
</p><p>You can see a snapshot of the progress of the tasks of the running job of the example in figure 8. 
</p><p>Each line represents a different task, each column represents a different compute-node where the task is executed on, with the exception of the first column that provides task descriptions. Cells that do not have a progress indicator represent nodes that either will not execute the task at all or they have not started executing the task yet. In the second case, a progress indicator will appear when the progress is updated to zero percent (0%) or more.
</p><p><br />
</p>
<div class="center"><div class="thumb tnone"><div class="thumbinner" style="width:302px;"><a href="./File:Hpc-workflow-manager-progress-running.png" class="image"><img alt="" src="_images/7/75/Hpc-workflow-manager-progress-running.png" width="300" height="196" class="thumbimage" /></a>  <div class="thumbcaption"><div class="magnify"><a href="./File:Hpc-workflow-manager-progress-running.png" class="internal" title="Enlarge"></a></div>Figure 8: The job is running and the progress indicators display the progress for each task on each compute-node.</div></div></div></div>
<h3><span class="mw-headline" id="Job_dashboard">Job dashboard</span></h3>
<p>In the “Job dashboard” there are the following five tabs:
</p>
<ul><li> “Macro Progress” – this tab is described in the previous section Inspecting progress (click <a rel="nofollow" class="external text" href="./File:Hpc-workflow-manager-macro-progress.png">here </a> );</li>
<li> “Error output” - the error output and warnings that are redirected live from the HPC Cluster (click <a rel="nofollow" class="external text" href="./File:Hpc-workflow-manager-error-output.png">here </a> );</li>
<li> “Other output”- the live redirected standard output from the cluster in the tab (click <a rel="nofollow" class="external text" href="./File:Hpc-workflow-manager-other-output.png">here </a> );</li>
<li> “Job directories” – contains a listing of the job directories (Input, Output and Working) (click <a rel="nofollow" class="external text" href="./File:Hpc-workflow-manager-job-directories.png">here </a> ); and</li>
<li> “Data upload” – contains a listing of the files that were uploaded (click <a rel="nofollow" class="external text" href="./File:Hpc-workflow-manager-data-upload.png">here </a> );</li></ul>
<h3><span class="mw-headline" id="How_to_download_the_results">How to download the results</span></h3>
<p>Once the job has finished you can right-click and select the item “Download result” which will now have become available.
</p><p>When the timer in the “Download” column has finished and the state is “Done” the files will have been transferred. You can see the downloaded files by right-clicking the job and selecting the item “Open job sub-directory”.
</p>
<h2><span class="mw-headline" id="How_to_write_a_parallel_Macro">How to write a parallel Macro</span></h2>
<h3><span class="mw-headline" id="Prerequisites">Prerequisites</span></h3>
<p>If you are new to Macro programming it is suggested to read <a href="Introduction_into_Macro_Programming" title="Introduction into Macro Programming">Introduction into Macro Programming</a> first. This will provide you with a sufficient introduction to the basics of Macro programming in Fiji.
</p><p>If you opt to use the script editor you may also find <a href="Using_the_Script_Editor" title="Using the Script Editor">Using the Script Editor</a> useful. Using the script editor is suggested as it supports autocompletion for the functions added by HPC Workflow Manager.
</p><p>You should also be familiar with the graphical user interface of the HPC Workflow Client.
</p>
<h3><span class="mw-headline" id="How_to_use_parallelization_function_.28by_example.29">How to use parallelization function (by example)</span></h3>
<p>Writing a small parallel script will make you familiar with the parallelization functionality offered to help you start using parallelism on Macro scripts.
</p>
<h4><span class="mw-headline" id="Simple_greeting_example">Simple greeting example</span></h4>
<p>Let's write a simple “greeting” Macro script where each node will greet the rest with a print message and wait for the rest to greet it as well. Then it will announce its departure and end. No node should finish before all of them have introduced themselves. Let’s start:
</p><p>First, we can write a serial version:
</p>
<pre class="brush:java">
print("The greeting program.");
print("Hello I am a single node.");
print("Bye, from the only node.");
</pre>
<p>Now let’s parallelize this by adding a call to <code>parInit()</code> at the beginning in order to start the parallel execution of the program. We must also add a call to <code>parFinalize()</code> at the end of our program to stop the parallelization. The code should now look like this:
</p>
<pre class="brush:java">
parInit();
  print("The greeting program.");
  print("Hello I am a single node.");
  print("Bye, from the only node.");
parFinalize();
</pre>
<p>Very well, our program is now parallelized. However, the messages no longer make sense.
</p><p>We should get the id of the node and print it instead as well as the total number of the nodes (just for fun).
</p><p>To get the id of the node (that is its rank) we must call <code>parGetRank()</code>.
</p>
<pre class="brush:java">
parInit();  
  myRank = parGetRank();
  if (myRank == 0){
    print("The greeting program.");
  }
  print("Hello I am node number: "+myRank);
  print("Bye, from node number: "+myRank);
parFinalize();
</pre>
<p>Notice that we also nested the first <code>print()</code> in an <code>if</code> statement comparing the rank with the first one (0), this is done in order to print this message only once. 
</p><p>You may choose any rank of the available nodes, it is not necessary to use the first one although it is the convention. You may run the script with a different amount of nodes in the future and the only rank that is guaranteed to exist is zero (0), this is because there will always be at least one node executing the script and it will have rank zero (0) assigned to it. Thus, the code surrounded in the <code>if</code> statement with rank zero will always be executed and executed by only one node.
</p><p>To greet all of the nodes let’s add the total number of nodes used to run the script (size) as well by calling get size <code>parGetSize()</code>. 
Add the following line after getting the rank to get the size:
</p>
<pre class="brush:java">
  size = parGetSize();
</pre>
<p>And modify the first print to read:
</p>
<pre class="brush:java">
  print("Hello to all "+size+" nodes. I am node number: "+myRank);
</pre>
<p>Very well, our program is now parallelized. Unfortunately, it is incorrect.
</p><p>If you run it enough times you will notice that sometimes a node will “depart” before all of them give their greetings. This is because some nodes may execute their code faster or slower, there is no guaranty that each line will execute at the same time, or which one will execute first between nodes.
</p><p>For example, if there are two (2) nodes the redirected output in the “Other output” tab could look like this:
</p>
<pre class="brush:text">
The greeting program.
Hello I am node number: 1
Bye, form node number: 1
Hello I am node number: 0
Bye, from node number: 0
</pre>
<p>To correct this we will put a barrier to the flow of the execution of the code.
</p>
<pre>Any node that calls this function will stop until every node has also called this function.
</pre>
<p>Do this by adding calling <code>parBarrier()</code> bellow the greeting and above the announcement of the departure of the node.
</p>
<pre class="brush:java">
  print("Hello I am node number: "+myRank);
  parBarrier();
  print("Bye, from node number: "+myRank);
</pre>
<p>The script will run correctly now, for example for three (3) nodes the following output may be printed:
</p>
<pre class="brush:text">
Hello I am node number: 1
Hello I am node number: 3
Hello I am node number: 0
Bye, form node number: 3
Bye, from node number: 0
Bye, from node number: 1
</pre>
<p>Which is correct.
Now let us imagine that node number one (1) and only node number one (1) brought with it a cake. And wants to share that information by printing it. You can have code executed in only specific nodes by using an <code>if</code> statement and comparing the rank like so:
</p>
<pre class="brush:java">
 if(myRank == 1){
   print("I brought the cake.");
 }
</pre>
<p>Add the above snippet anywhere in the parallel region (that is between <code>parInit()</code> and <code>parFinalize()</code>) and before calling <code> parBarrier()</code>.
</p><p>Great, now since node one brought the cake it would like to share it with the rest of the nodes. Let’s imagine that the cake is an array made out of numbers. Like the following one:
</p>
<pre class="brush:java">
  cake = newArray(1, 2, 3, 4);
</pre>
<p>There are four pieces of cake. Add the above line inside the <code>if</code> statement’s body. Above the <code>if</code> statement add the following:
</p>
<pre class="brush:java">
  cake = newArray(0);
</pre>
<p>Which means that the rest of the nodes do not have a cake. You will understand why this is necessary later.
</p><p>Node number one wants to divide them equally. This is why <code>parScatterEqually()</code> must be used.
</p><p><code>parScatterEqually()</code> will at the same time send and receive the cake piece or pieces (array items). It needs three arguments, the array to split as well as send (scatter), the length of the sent array, and which node is to spit the array and send it. Thus, in this case, you must add the bellow line after the <code>if</code> statement’s body:
</p>
<pre class="brush:java">
  receivedPieces = parScatterEqually(cake, 4, 1); // Do NOT use lengthOf(cake);
</pre>
<p>Remember the rest of the nodes do not have a cake and cannot know its size!
All nodes including one (1) will receive parts of the cake. Since there are more than three pieces of cake the first node (rank == 0) will get the extra piece. (<code>parScatterEqually()</code> will always give any extra array elements to the first node, to avoid this one must use <code>parScatter()</code> and specify exactly how many elements is each node to receive).
</p><p>Now you may print the piece or pieces that the node received. This is the last step of the example in this section. Overall, the code should now look like this:
</p>
<pre class="brush:java">
parInit();
  myRank = parGetRank();
  if(myRank == 0){
    print("The greeting program.");
  }
  size = parGetSize();
  print("Hello to all "+size+" nodes. I am node number: "+myRank);
  cake = newArray(0);
  if(myRank == 1){
    print("I brought the cake.");
    cake = newArray(1, 2, 3, 4);
  }
  receivedPieces = parScatterEqually(cake, 4, 1);
  parBarrier();
  for(i = 0; i &lt; lengthOf(receivedPieces); i++){
    print("I node number "+myRank+" received piece: "+receivedPieces[i]);
  }
  print("Bye, from node number: "+myRank);
parFinalize();
</pre>
<p>Lastly, something important to remember is that nodes do not share memory. Each node is separate, they can only communicate through messages (sending data). Currently only by calling <code>parScatterEqually()</code> or <code>parScatter()</code>.
</p>
<h3><span class="mw-headline" id="How_to_use_the_progress_reporting_functions_.28by_example.29">How to use the progress reporting functions (by example)</span></h3>
<p>The first step is to add all tasks by using the <code>parAddTasks()</code> function. Simply call this method after <code>parInit()</code> as many times as the tasks that you want to have including a unique description for each one of them. The description must be unique. The tasks are automatically assigned an auto-incremented id in the order they were added.
</p><p>You may store the id of the task added in a variable for easier handling later on.
</p><p>The second step is to call the <code>parReportTasks()</code> function which will output to each node’s progress log a listing of the task id along with the task’s description.
</p><p>Notice that the task ids may differ between nodes as a task may be added only in one node if so desired by the user.
</p><p>The third step is to call the <code>parReportProgress()</code> function which will add the current progress to the progress report file.
</p><p>Note that progress can be only a percentage between 0 and 100 and it cannot move backward.
</p><p>Other information may be reported by calling the <code>parReportText()</code> function.
</p>
<h4><span class="mw-headline" id="Expanding_on_the_greeting_example">Expanding on the greeting example</span></h4>
<p>Expanding on the previous example of the nodes greeting each other and sharing a cake we now add the necessary function calls to report the progress of each task.
</p><p>The example can be split into four(4) tasks:
</p>
<ol><li> A node introduces itself to all other nodes. (Gets the rank and size and prints them.)</li>
<li> Node number one (1) gets the cake. (Creates the array with the data.)</li>
<li> Each node receives some pieces of the cake. (The node receives the elements of the array, node one also sends the pieces to all nodes including itself.)</li>
<li> Each node announces the pieces that they got. (Print the elements in the received array.)</li></ol>
<p>Take a look at the code featured at the end of this section which will be explained in detail here.
</p><p>Notice that task number three (3) is nested in an <code>if</code> statement. This is because we want only one node to create the cake (data). 
</p><p>In a real problem, the data could be a giant dataset that is available only on one computer and we want to send parts of it to the other nodes that will perform some computations using their part of the data.
</p><p>Be careful, since the task is added only on node one (1) the indices of the tasks after it will be different in the rest of the nodes by one.
</p><p>For example, the following two nodes will have different task numbers for the same tasks in the list presented earlier in this section: 
</p>
<ul><li> node zero (0) will have: list(1) -&gt; id(0), list(3) -&gt; id(1), list(4) -&gt; id(2).</li>
<li> while node (1) will have: list(1) -&gt; id(0), list(2) -&gt; id(1), list(3) -&gt; id(2), list(4) -&gt; id(3).</li></ul>
<p>This can cause great difficulty, this is why it is suggested to always store the task id returned when adding the task in a variable and use it instead.
</p>
<pre class="brush:java">
parInit();
  introductionTask = parAddTask("Introduction to other nodes.");
  
  myRank = parGetRank();
  size = parGetSize();
  
  if(myRank == 1){
    print("The greeting program. Now with progress reporting!");
    cakeTask = parAddTask("Get the cake.");
  }
  getPieceTask = parAddTask("Get the cake pieces.");
  annoucementTask = parAddTask("Announce the pieces you got.");
  parReportTasks();

  parReportProgress(introductionTask,0);
  print("Hello to all "+size+" nodes. I am node number: "+myRank);
  parReportProgress(introductionTask, 100);
  
  cake = newArray(0);
  if(myRank == 1){
    parReportProgress(cakeTask, 0);
    print("I brought the cake.");
    cake = newArray(30);
      for(i = 0; i &lt; lengthOf(cake); i++){
        cake[i] = i;
        parReportProgress(cakeTask, i/30 * 100);
      }
      parReportProgress(cakeTask, 100);
  }
  
  parReportProgress(getPieceTask, 0);
  receivedPieces = parScatterEqually(cake, 10, 1);
  parReportProgress(getPieceTask, 100);
  
  parBarrier();
  
  parReportProgress(annoucementTask, 0);
  for(i = 0; i &lt; lengthOf(receivedPieces); i++){
    print("I node number "+myRank+" received piece: "+receivedPieces[i]);
	parReportProgress(annoucementTask, i/lengthOf(receivedPieces)*100);
  }
  parReportProgress(annoucementTask, 100);
  
  print("Bye, from node number: "+myRank);
parFinalize();
</pre>
<div class="center"><div class="thumb tnone"><div class="thumbinner" style="width:302px;"><a href="./File:Hpc-workflow-manager-progress-no-task.png" class="image"><img alt="" src="_images/6/6b/Hpc-workflow-manager-progress-no-task.png" width="300" height="214" class="thumbimage" /></a>  <div class="thumbcaption"><div class="magnify"><a href="./File:Hpc-workflow-manager-progress-no-task.png" class="internal" title="Enlarge"></a></div>Figure 9: The job has finished and all the progress indicators are present. Note that the task "Get the cake" has a progress indicator only on node one (1) as expected. This is because this task was added in an <code>if</code> statement checking that the rank is one.</div></div></div></div>
<div class="center"><div class="thumb tnone"><div class="thumbinner" style="width:802px;"><a href="./File:Hpc-workflow-manager-side-by-side-example.png" class="image"><img alt="" src="_images/a/a8/Hpc-workflow-manager-side-by-side-example.png" width="800" height="646" class="thumbimage" /></a>  <div class="thumbcaption"><div class="magnify"><a href="./File:Hpc-workflow-manager-side-by-side-example.png" class="internal" title="Enlarge"></a></div>Figure 10: The red circle labeled zero (0) is a task performed by all nodes. It is first added, and then its progress is reported twice: once when it is zero and finally when it is done. The green circle labeled three (3) is first added and then its progress is reported as well, however, notice that all its related commands are inside the body of <code>if</code> statements. Notice that all calls of <code>parAddTask()</code> are before <code>parReportTasks()</code>.</div></div></div></div>
<h3><span class="mw-headline" id="Available_functions_.28list.29">Available functions (list)</span></h3>
<p>Many of the functions have an MPI equivalent, this will also be listed in the table to aid people familiar with MPI. This is because the current implementation uses OpenMPI 4.0. Note however that this does not mean that this will be a wrapper for MPI for Fiji Macro and the underlying implementation may and probably will change.
</p>
<table class="wikitable">
<caption> Parallelization functions
</caption>
<tr>
<th> Function name </th>
<th> Input </th>
<th> Output </th>
<th> Description </th>
<th> MPI equivalent
</th></tr>
<tr>
<td> parInit </td>
<td> None      </td>
<td> None </td>
<td> Initializes parallelization, it should be called at the beginning of the parallel code. </td>
<td> MPI_Init
</td></tr>
<tr>
<td> parFinalize </td>
<td> None </td>
<td> None </td>
<td> Finalizes parallelization, it should be called at the end of the parallel code. </td>
<td> MPI_Finalize
</td></tr>
<tr>
<td> parGetRank </td>
<td> None </td>
<td> Id of the current node. </td>
<td> Returns the id of the current node. </td>
<td> MPI_Comm_rank
</td></tr>
<tr>
<td> parGetSize </td>
<td> None </td>
<td> Total number of nodes. </td>
<td> Returns the total number of nodes. </td>
<td> MPI_Comm_size
</td></tr>
<tr>
<td> parBarrier </td>
<td> None </td>
<td> None </td>
<td> Parallel barrier, all nodes must reach the point of calling this function for any of them to continue further. Provides synchronization. </td>
<td> MPI_Barrier
</td></tr>
<tr>
<td> parScatterEqually </td>
<td> An array to split and send, the length of the array to send, the rank of the node that will split and send the array. </td>
<td> An array. </td>
<td> This will try to split an array to equal parts send it from the given rank. It will also receive the part of the array it should and return it (including the rank that sends the parts). In case the number of array elements is not equally divisible it will send any extra elements to the first rank (0). </td>
<td> None
</td></tr>
<tr>
<td> parScatter </td>
<td> An array to split and send, number of elements to send, number of elements to receive and the rank of the node to send the elements. </td>
<td> An array. </td>
<td> This works like parScatterEqually but in this case the user is responsible for providing the parameters to split the array. </td>
<td> MPI_Scatter
</td></tr>
<tr>
<td> parGather </td>
<td> An array to send, number of items to send, number of items to receive, receiver's rank</td>
<td> An array. </td>
<td> All ranks send an equal amount of array items to a single node of a given rank. Be careful, the receiveCount parameter should be the count of items received from each rank separately. This is the inverse operation of parScatter. </td>
<td> MPI_Gather
</td></tr>
<tr>
<td> parGatherEqually </td>
<td> An array to send, number of elements in received array, receiver's rank </td>
<td> An array. </td>
<td> The given rank will receive an array send in parts by all ranks. This is the inverse operation of the parScatterEqually. </td>
<td> None
</td></tr></table>
<table class="wikitable">
<caption> Progress log functions
</caption>
<tr>
<th> Function name </th>
<th> Input </th>
<th> Output </th>
<th> Description
</th></tr>
<tr>
<td> parReportProgress </td>
<td> Task id (ex 8), progress percentage (ex 85&#160;%) </td>
<td> None </td>
<td> Outputs progress in percentage for a specified task in the node’s progress log.
</td></tr>
<tr>
<td> parReportText </td>
<td> Text </td>
<td> None </td>
<td> Outputs given text to the node’s log.
</td></tr>
<tr>
<td> parAddTask </td>
<td> Description </td>
<td> Index of added task. </td>
<td> Creates a new task with the description provided.
</td></tr>
<tr>
<td> parReportTasks </td>
<td> None </td>
<td> None </td>
<td> Outputs all task ids with their descriptions.
</td></tr>
<tr>
<td> parEnableTiming </td>
<td> None </td>
<td> None </td>
<td> Enables timing each task in the progress logs. It measures time passed to reach 100% from 0% progress.
</td></tr></table>
<p>If you need help remembering the functions and what they do you may use autocompletion to get help. Just type "par" and a list of options will appear. There is a link to this page in the autocomplete help. An example is provided in figure 10.
</p>
<div class="center"><div class="thumb tnone"><div class="thumbinner" style="width:302px;"><a href="./File:Hpc-workflow-manager-autocomplete.png" class="image"><img alt="" src="_images/c/cb/Hpc-workflow-manager-autocomplete.png" width="300" height="230" class="thumbimage" /></a>  <div class="thumbcaption"><div class="magnify"><a href="./File:Hpc-workflow-manager-autocomplete.png" class="internal" title="Enlarge"></a></div>Figure 11: Function autocompletion example.</div></div></div></div>
<h2><span class="mw-headline" id="Installation">Installation</span></h2>
<p>HPC Workflow Manager client is available to install through its update site.
</p>
<h3><span class="mw-headline" id="Instructions">Instructions</span></h3>
<ul><li> <a rel="nofollow" class="external text" href="Fiji/Downloads">Download</a> install and launch Fiji;</li>
<li> go to <span><em><span style="border-bottom:1px dotted #ccc;"> Help </span>&#160;&#8250; <span style="border-bottom:1px dotted #ccc;"> Update... </span>&#160;&#8250; <span style="border-bottom:1px dotted #ccc;"> Manage update sites</span></em></span>;</li>
<li> tick "P2E-IT4Innovations";</li>
<li> close the window;</li>
<li> click "Apply changes"; and</li>
<li> restart Fiji.</li></ul>

<!-- 
NewPP limit report
Cached time: 20200713072427
Cache expiry: 86400
Dynamic content: false
CPU time usage: 0.052 seconds
Real time usage: 0.056 seconds
Preprocessor visited node count: 278/1000000
Preprocessor generated node count: 930/1000000
Post‐expand include size: 506/2097152 bytes
Template argument size: 78/2097152 bytes
Highest expansion depth: 6/40
Expensive parser function count: 0/3
-->

<!-- 
Transclusion expansion time report (%,ms,calls,template)
100.00%    4.391      1 - -total
100.00%    4.391      1 - Template:Bc
 28.74%    1.262      2 - Template:Arrow
-->
</div><div class="printfooter">
Retrieved from "<a dir="ltr" href="index.php?title=HPC_Workflow_Manager&amp;oldid=45684">http://imagej.net/index.php?title=HPC_Workflow_Manager&amp;oldid=45684</a>"</div>
							</div>

			<div id="footer">
				<p> This page was last modified on 15 June 2020, at 07:07.</p><ul><li><a href="./ImageJ:Privacy_policy" title="ImageJ:Privacy policy">Privacy policy</a></li><li><a href="./ImageJ:About" class="mw-redirect" title="ImageJ:About">About ImageJ</a></li><li><a href="Imprint" title="Imprint">Imprint</a></li></ul>			</div>

			<div id="catlinks" class="catlinks catlinks-allhidden" data-mw="interface"></div>		</div>

		<div id="bottom-wrap">
		</div>
		<script>(window.RLQ=window.RLQ||[]).push(function(){mw.loader.load(["ext.fancytree","ext.suckerfish","mediawiki.toc","mediawiki.action.view.postEdit","site","mediawiki.user","mediawiki.hidpi","mediawiki.page.ready","mediawiki.searchSuggest","ext.SimpleTooltip"]);});</script><script>(window.RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgBackendResponseTime":236});});</script>
		</body>
		</html>
		