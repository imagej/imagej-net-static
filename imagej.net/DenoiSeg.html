<!DOCTYPE html>
<html class="client-nojs" lang="en" dir="ltr">
<head>
<meta charset="UTF-8"/>
<title>DenoiSeg - ImageJ</title>
<script>document.documentElement.className = document.documentElement.className.replace( /(^|\s)client-nojs(\s|$)/, "$1client-js$2" );</script>
<script>(window.RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgCanonicalNamespace":"","wgCanonicalSpecialPageName":false,"wgNamespaceNumber":0,"wgPageName":"DenoiSeg","wgTitle":"DenoiSeg","wgCurRevisionId":45828,"wgRevisionId":45828,"wgArticleId":12724,"wgIsArticle":true,"wgIsRedirect":false,"wgAction":"view","wgUserName":null,"wgUserGroups":["*"],"wgCategories":[],"wgBreakFrames":false,"wgPageContentLanguage":"en","wgPageContentModel":"wikitext","wgSeparatorTransformTable":["",""],"wgDigitTransformTable":["",""],"wgDefaultDateFormat":"dmy","wgMonthNames":["","January","February","March","April","May","June","July","August","September","October","November","December"],"wgMonthNamesShort":["","Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec"],"wgRelevantPageName":"DenoiSeg","wgRelevantArticleId":12724,"wgRequestId":"9013fc887f36c398a2844337","wgIsProbablyEditable":false,"wgRestrictionEdit":[],"wgRestrictionMove":[],"wgPreferredVariant":"en","fancytree_path":"/extensions/TreeAndMenu/fancytree"});mw.loader.state({"site.styles":"ready","noscript":"ready","user.styles":"ready","user.cssprefs":"ready","user":"ready","user.options":"loading","user.tokens":"loading","mediawiki.legacy.shared":"ready","mediawiki.legacy.commonPrint":"ready","mediawiki.sectionAnchor":"ready","skins.erudite":"ready"});mw.loader.implement("user.options@0j3lz3q",function($,jQuery,require,module){mw.user.options.set({"variant":"en"});});mw.loader.implement("user.tokens@1ku9xth",function ( $, jQuery, require, module ) {
mw.user.tokens.set({"editToken":"+\\","patrolToken":"+\\","watchToken":"+\\","csrfToken":"+\\"});/*@nomin*/;

});mw.loader.load(["mediawiki.page.startup"]);});</script>
<link rel="stylesheet" href="erudite14.css"/>
<link rel="stylesheet" href="extensions/TreeAndMenu/fancytree/fancytree.css"/><link rel="stylesheet" href="extensions/TreeAndMenu/suckerfish/suckerfish.css"/>
<meta name="ResourceLoaderDynamicStyles" content=""/>
<link rel="stylesheet" href="erudite15.css"/>
<meta name="generator" content="MediaWiki 1.28.0"/>
<meta name="description" content="DenoiSeg is a neural network based algorithm for instance segmentation.&#10;The interesting thing about DenoiSeg is, that - although primarily meant for segmentation - the algorithm also learns to denoise your images.&#10;The knowledge acquired by denoising the images, improves the segmentation results.&#10;DenoiSeg can solve hard segmentation tasks,&#10;just like other neural network bases algorithms. &#10;But it requires less training data, you only need to manually generate segmentation for about 2 to 10 images. (Other methods usually require much manual segmentations for at least 50 image.)"/>
<link rel="shortcut icon" href="skins/ij2.ico"/>
	<meta property="og:type" content="article"/>

	<meta property="og:site_name" content="ImageJ"/>

	<meta property="og:title" content="DenoiSeg"/>

	<meta property="og:description" content="DenoiSeg is a neural network based algorithm for instance segmentation.&#10;The interesting thing about DenoiSeg is, that - although primarily meant for segmentation - the algorithm also learns to denoise your images.&#10;The knowledge acquired by denoising the images, improves the segmentation results.&#10;DenoiSeg can solve hard segmentation tasks,&#10;just like other neural network bases algorithms. &#10;But it requires less training data, you only need to manually generate segmentation for about 2 to 10 images. (Other methods usually require much manual segmentations for at least 50 image.)"/>


<meta name="viewport" content="width=device-width, initial-scale=1" />
</head>
<body class="mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject page-DenoiSeg rootpage-DenoiSeg skin-erudite action-view">
		<div id="top-wrap" role="banner">
			<h1><a href="Welcome" title="ImageJ" rel="home">ImageJ</a></h1>
			<div id="tagline">From ImageJ</div>

			<a id="menubutton" href="DenoiSeg.html#menu">Menu</a>
			<div id="nav" role="navigation">
			<ul id='menu'>
<li id="menu-item-n-About"><a href="ImageJ">About</a></li>
<li id="menu-item-n-Downloads"><a href="Downloads">Downloads</a></li>
<li id="menu-item-n-Learn"><a href="Learn">Learn</a></li>
<li id="menu-item-n-Develop"><a href="Development">Develop</a></li>
<li id="menu-item-n-News"><a href="News">News</a></li>
<li id="menu-item-n-Events"><a href="Events">Events</a></li>
<li id="menu-item-n-Help"><a href="Help">Help</a></li>
</ul>
			</div>
		</div>

		<div id="mw-js-message"></div>
		
		<div id="main" role="main">

			<div id="bodyContent">
				<div style="font-size: large; border: 1px solid black; padding: 1em; margin-bottom: 1em; text-align: center; background-color: #fda;">
					This is a read-only version of imagej.net, available during the transition to a new site.
					<br>Please direct any questions or issues to <a href="https://forum.image.sc/t/imagej-wiki-is-down/39672">this Image.sc Forum thread</a>.
					<br>Thank you for your patience as we improve the website!
				</div>

				<h1>DenoiSeg</h1>
				
				<div id="mw-content-text" lang="en" dir="ltr" class="mw-content-ltr"><div class="thumb tright"><div class="thumbinner" style="width:302px;"><a href="./File:DenoiSeg-teaser.png" class="image"><img alt="" src="_images/b/b0/DenoiSeg-teaser.png" width="300" height="300" class="thumbimage" /></a>  <div class="thumbcaption"><div class="magnify"><a href="./File:DenoiSeg-teaser.png" class="internal" title="Enlarge"></a></div>Teaser of what DenoiSeg can compute on your data.</div></div></div>
<p>DenoiSeg is a neural network based algorithm for instance segmentation.
The interesting thing about DenoiSeg is, that - although primarily meant for segmentation - the algorithm also learns to denoise your images.
The knowledge acquired by denoising the images, improves the segmentation results.
DenoiSeg can solve hard segmentation tasks,
just like other neural network bases algorithms. 
But it requires less training data, you only need to manually generate segmentation for about 2 to 10 images. (Other methods usually require much manual segmentations for at least 50 image.)
</p><p>This website describes the DenoiSeg FIJI Plugin. Which makes it very easy to use DenoiSeg. All you need is your images, manually generated segmentations for a few of them, a computer with a NVIDIA graphics card and FIJI installed.
</p><p>Segmenting your data with DenoiSeg requires 3 steps: 
</p>
<ol><li> Create manual segmentations for few of your images. (This might take around 8 h of manual work.)</li>
<li> Train the neural network. The result is a trained neural network, which is called: model. (Training keeps your computer busy for around 12 h. This can be done over night, as you don't need do anything.)</li>
<li> Prediction: Use the train model to segment as much images as you want. This step is much faster, just 1 second per image. </li></ol>
<p>This FIJI plugin is part of CSBDeep, a collection of neural network algorithm in FIJI. For more information about our open source implementation , examples and images, click <a rel="nofollow" class="external text" href="https://csbdeep.bioimagecomputing.com/tools/denoiseg/">here</a>.
</p>
<div id="toc" class="toc"><div id="toctitle"><h2>Contents</h2></div>
<ul>
<li class="toclevel-1 tocsection-1"><a href="./DenoiSeg.html#Publication:_DenoiSeg_-_Joint_Denoising_and_Segmentation"><span class="tocnumber">1</span> <span class="toctext">Publication: DenoiSeg - Joint Denoising and Segmentation</span></a></li>
<li class="toclevel-1 tocsection-2"><a href="DenoiSeg.html#Installation"><span class="tocnumber">2</span> <span class="toctext">Installation</span></a></li>
<li class="toclevel-1 tocsection-3"><a href="DenoiSeg.html#Usage"><span class="tocnumber">3</span> <span class="toctext">Usage</span></a>
<ul>
<li class="toclevel-2 tocsection-4"><a href="DenoiSeg.html#Training"><span class="tocnumber">3.1</span> <span class="toctext">Training</span></a>
<ul>
<li class="toclevel-3 tocsection-5"><a href="DenoiSeg.html#Prepare_your_data"><span class="tocnumber">3.1.1</span> <span class="toctext">Prepare your data</span></a></li>
<li class="toclevel-3 tocsection-6"><a href="DenoiSeg.html#Example_data"><span class="tocnumber">3.1.2</span> <span class="toctext">Example data</span></a></li>
<li class="toclevel-3 tocsection-7"><a href="DenoiSeg.html#Train_plugin"><span class="tocnumber">3.1.3</span> <span class="toctext">Train plugin</span></a></li>
<li class="toclevel-3 tocsection-8"><a href="DenoiSeg.html#Train_.26_predict_plugin_.28one-click_solution.29"><span class="tocnumber">3.1.4</span> <span class="toctext">Train &amp; predict plugin (one-click solution)</span></a></li>
</ul>
</li>
<li class="toclevel-2 tocsection-9"><a href="DenoiSeg.html#What_happens_during_and_after_training"><span class="tocnumber">3.2</span> <span class="toctext">What happens during and after training</span></a></li>
<li class="toclevel-2 tocsection-10"><a href="DenoiSeg.html#Prediction"><span class="tocnumber">3.3</span> <span class="toctext">Prediction</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-11"><a href="DenoiSeg.html#Exporting_trained_models_from_Python_to_ImageJ_.2F_Fiji"><span class="tocnumber">4</span> <span class="toctext">Exporting trained models from Python to ImageJ / Fiji</span></a></li>
<li class="toclevel-1 tocsection-12"><a href="DenoiSeg.html#Creating_labelings_for_the_training"><span class="tocnumber">5</span> <span class="toctext">Creating labelings for the training</span></a></li>
</ul>
</div>

<h1><span class="mw-headline" id="Publication:_DenoiSeg_-_Joint_Denoising_and_Segmentation">Publication: DenoiSeg - Joint Denoising and Segmentation</span></h1>
<p><b>Abstract</b>
</p><p>Microscopy image analysis often requires the segmentation of objects, but training data for this task is typically scarce and hard to obtain. Here we propose DenoiSeg, a new method that can be trained end-to-end on only a few annotated ground truth segmentations. We achieve this by extending Noise2Void, a self-supervised denoising scheme that can be trained on noisy images alone, to also predict dense 3-class segmentations. The reason for the success of our method is that segmentation can profit from denoising, especially when performed jointly within the same network. The network becomes a denoising expert by seeing all available raw data, while co-learning to segment, even if only a few segmentation labels are available. This hypothesis is additionally fueled by our observation that the best segmentation results on high quality (very low noise) raw data are obtained when moderate amounts of synthetic noise are added. This renders the denoising-task non-trivial and unleashes the desired co-learning effect. We believe that DenoiSeg offers a viable way to circumvent the tremendous hunger for high quality training data and effectively enables few-shot learning of dense segmentations.
</p><p><b><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2005.02987">Full-text</a></b>
</p>
<h1><span class="mw-headline" id="Installation">Installation</span></h1>
<p>The DenoiSeg FIJI Plugin is part of the CSBDeep update site. Look <a rel="nofollow" class="external text" href="Following_an_update_site">here</a>, for detailed instructions on how to install an update site. Or just follow these steps:
</p>
<ol><li> Start ImageJ / Fiji</li>
<li> Open the updater via <code>Help &gt; Update...</code></li>
<li> Click on <code>Manage update sites</code></li>
<li> Select the <b><code>CSBDeep</code></b> update site</li>
<li> Click on <code>Apply changes</code></li>
<li> (optional) read <a rel="nofollow" class="external text" href="TensorFlow-GPU">this page</a> for GPU support</li>
<li> Restart ImageJ / Fiji</li></ol>
<p>You should now have access to these plugins:
</p>
<img src="_images/denoiseg/csb_deep_plugin.png", width="300", height="100">
<h1><span class="mw-headline" id="Usage">Usage</span></h1>
<h2><span class="mw-headline" id="Training">Training</span></h2>
<p>Read <a rel="nofollow" class="external text" href="TensorFlow-GPU">this page</a> for how to get GPU support. With out a GPU the training will take ages.
</p>
<h3><span class="mw-headline" id="Prepare_your_data">Prepare your data</span></h3>
<ul><li> create two folders for training and two folders for validation, name them e.g. <code>X_train</code>, <code>Y_train</code>, <code>X_val</code>, and <code>Y_val</code></li>
<li> Put noisy images into <code>X_train</code>, the more the better</li>
<li> Label some of them carefully - the more the better, but a handful labelings of high quality can be sufficient as well. Each labeling should be zero where there is background and the same integer number for each pixel of the same object.</li>
<li> Put the labels into <code>Y_train</code> - each labeling file needs to have the same name as the matching raw data in <code>X_train</code></li>
<li> Do the same for <code>X_val</code> and <code>Y_val</code>. Aim for having about 10% validation data and 90% training data. If in doubt, use more data for training.</li></ul>
<h3><span class="mw-headline" id="Example_data">Example data</span></h3>
<p>If you just want to test the FIJI plugin you may use this <a rel="nofollow" class="external text" href="https://cloud.mpi-cbg.de/index.php/s/Mayv4JHOlR6ykBh">data</a>. It was used to create the screenshots below.
</p><p>Please note: You may not use this training data to segment your images. You need to prepare your own training data to get good results for your images.
</p>
<h3><span class="mw-headline" id="Train_plugin">Train plugin</span></h3>
<div class="thumb tright"><div class="thumbinner" style="width:302px;"><a href="./File:Denoiseg-train-parameters.png" class="image"><img alt="" src="_images/d/d9/Denoiseg-train-parameters.png" width="300" height="211" class="thumbimage" /></a>  <div class="thumbcaption"><div class="magnify"><a href="./File:Denoiseg-train-parameters.png" class="internal" title="Enlarge"></a></div>N2V train parameters</div></div></div>
<ol><li> Start ImageJ / Fiji</li>
<li> Click on <code>Plugins &gt; CSBDeep &gt; DenoiSeg &gt; DenoiSeg train</code> and adjust the following parameters:
<ul><li> <b><code>Folder containing training raw images</code></b> Choose the folder we called <code>X_train</code> in the above data preparation section. It contains raw noisy data.</li>
<li> <b><code>Folder containing training labeling images</code></b> Choose the folder we called <code>Y_train</code> in the above data preparation section. It contains some labelings matching the raw noisy data.</li>
<li> <b><code>Folder containing validation raw images</code></b> Choose the folder we called <code>X_val</code> in the above data preparation section. It contains raw noisy data for judging the quality of the training progress.</li>
<li> <b><code>Folder containing validation labeling images</code></b> Choose the folder we called <code>Y_val</code> in the above data preparation section. It contains some labelings matching the raw noisy validation data.</li>
<li> <b><code>Number of epochs</code></b> How many epochs should be performed during training</li>
<li> <b><code>Number of steps per epoch</code></b> How many steps per epoch should be performed</li>
<li> <b><code>Batch size per step</code></b> How many tiles are batch processed by the network per training step</li>
<li> <b><code>Patch shape</code></b> The length of X, Y (and Z) of one training patch (needs to be a multiple of 16)</li>
<li> <b><code>Neighborhood radius</code></b> N2V specific parameter describing the distance of the neighbor pixel replacing the center pixel</li></ul></li>
<li> Click <code>Ok</code></li>
<li> Look below at the <a href="DenoiSeg.html#What_happens_during_and_after_training">What happens during and after training</a> section for what happens next</li></ol>
<h3><span class="mw-headline" id="Train_.26_predict_plugin_.28one-click_solution.29">Train &amp; predict plugin (one-click solution)</span></h3>
<div class="thumb tright"><div class="thumbinner" style="width:302px;"><a href="./File:Denoiseg-trainpredict-parameters.png" class="image"><img alt="" src="_images/f/f5/Denoiseg-trainpredict-parameters.png" width="300" height="248" class="thumbimage" /></a>  <div class="thumbcaption"><div class="magnify"><a href="./File:Denoiseg-trainpredict-parameters.png" class="internal" title="Enlarge"></a></div>N2V train &amp; predict parameters</div></div></div>
<ol><li> Start ImageJ / Fiji</li>
<li> Open a noisy image you want to denoise and segment directly after training</li>
<li> Click on <code>Plugins &gt; CSBDeep &gt; DenoiSeg &gt; DenoiSeg train &amp; predict</code> and adjust the following parameters:
<ul><li> <b><code>Raw prediction input image</code></b> Choose the image which should be denoised and segmented after training</li>
<li> <b><code>Axes of prediction input</code></b> This parameter helps to figure out how your input data is organized. It's a string with one letter per dimension of the input image. For 2D images, this should be <code>XY</code>. If your data has another axis which should be batch processed, set this parameter to <code>XYB</code></li>
<li> Regarding the other parameters please have a look at the descriptions in <a href="DenoiSeg.html#Train_plugin">Train plugin</a></li></ul></li>
<li> Click <code>Ok</code></li>
<li> Look below at the <a href="DenoiSeg.html#What_happens_during_and_after_training">What happens during and after training</a> section for what happens next</li></ol>
<h2><span class="mw-headline" id="What_happens_during_and_after_training">What happens during and after training</span></h2>
<div class="thumb tright"><div class="thumbinner" style="width:302px;"><a href="./File:Denoiseg-train-progress.png" class="image"><img alt="" src="_images/4/4b/Denoiseg-train-progress.png" width="300" height="301" class="thumbimage" /></a>  <div class="thumbcaption"><div class="magnify"><a href="./File:Denoiseg-train-progress.png" class="internal" title="Enlarge"></a></div>DenoiSeg training progress window</div></div></div>
<div class="thumb tright"><div class="thumbinner" style="width:302px;"><a href="./File:Denoiseg-train-preview.png" class="image"><img alt="" src="_images/5/58/Denoiseg-train-preview.png" width="300" height="88" class="thumbimage" /></a>  <div class="thumbcaption"><div class="magnify"><a href="./File:Denoiseg-train-preview.png" class="internal" title="Enlarge"></a></div>N2V training preview window</div></div></div>
<p>During training, you will see two windows:
</p>
<ul><li> The progress window keeps you updated of the steps the training process is going through. It also plots the current training and validation loss. </li>
<li> The preview window is generated from the first validation batch. It is split into five parts. 
<ol><li> the original noisy data</li>
<li> the predicted denoised image</li>
<li> the predicted probability if each pixel being on the background</li>
<li> the predicted probability if each pixel being on the foreground</li>
<li> the predicted probability if each pixel being on the border</li></ol></li></ul>
<p>After training, two additional windows should appear. They represent two trained models. One is the model from the epoch with the lowest validation loss, the other one the model from the last epoch step. For DenoiSeg, using the model from the last epoch is almost always recommended. The windows will look similar to this:
</p>
<div class="MediaTransformError" style="width: 602px; height: 0px; display:inline-block;">Error creating thumbnail: Unable to save thumbnail to destination</div>
<p>They are stored to a temporary location which you can see in the Overview section of the model window under <code>Saved to..</code>. 
</p><p><b>Copy the model from there to another permanent destination on your disk if you want to keep this trained model.</b>
</p>
<h2><span class="mw-headline" id="Prediction">Prediction</span></h2>
<p>There are two ways to predict from a trained model. For both cases, the resulting image will consist of four channels:
</p>
<ol><li> the denoised image</li>
<li> the probability of each pixel being on the background</li>
<li> the probability of each pixel being on the foreground</li>
<li> the probability of each pixel being on the border</li></ol>
<p>The user currently has to use these probabilities to compute the segmentation themself. In the future, further postprocessing steps will be available to automatically compute segmentations based on the output of the trained model. 
</p><p>You can <b>open the model directly</b>:
</p>
<div class="thumb tright"><div class="thumbinner" style="width:302px;"><a href="./File:Denoiseg-modelpredict-parameters.png" class="image"><img alt="" src="_images/8/81/Denoiseg-modelpredict-parameters.png" width="300" height="92" class="thumbimage" /></a>  <div class="thumbcaption"><div class="magnify"><a href="./File:Denoiseg-modelpredict-parameters.png" class="internal" title="Enlarge"></a></div>DenoiSeg prediction from model parameters</div></div></div>
<ol><li> Start Fiji</li>
<li> Open an image you want to denoise and segment and for which you have a pretrained model available as ZIP file</li>
<li> Click <code>Import &gt; bioimage.io.zip</code> and choose your trained model. The model will open in a window as depicted above</li>
<li> Click <code>Predict</code> in the model window and adjust the following parameters:
<ul><li> <b><code>Input</code></b> The image you want to denoise</li>
<li> <b><code>Axes of prediction input</code></b> This parameter helps to figure out how your input data is organized. It's a string with one letter per dimension of the input image. For 2D images, this should be <code>XY</code>. If your data has another axis which should be batch processed, set this parameter to <code>XYB</code></li></ul></li></ol>
<p>Alternatively, you can <b>use the DenoiSeg menu</b>:
</p>
<div class="thumb tright"><div class="thumbinner" style="width:302px;"><a href="./File:Denoiseg-predict-parameters.png" class="image"><img alt="" src="_images/6/69/Denoiseg-predict-parameters.png" width="300" height="81" class="thumbimage" /></a>  <div class="thumbcaption"><div class="magnify"><a href="./File:Denoiseg-predict-parameters.png" class="internal" title="Enlarge"></a></div>DenoiSeg prediction parameters</div></div></div>
<ol><li> Start Fiji</li>
<li> Open an image you want to denoise and for which you have a pretrained model available as ZIP file</li>
<li> Click <code>Plugins &gt; DenoiSeg &gt; DenoiSeg predict</code> and adjust the parameters as described above, with this addition:
<ul><li> <b><code>Trained model file</code></b> The ZIP file containing the pretrained model (it should end with <code>.bioimage.io.zip</code>)</li></ul></li></ol>
<h1><span class="mw-headline" id="Exporting_trained_models_from_Python_to_ImageJ_.2F_Fiji">Exporting trained models from Python to ImageJ / Fiji</span></h1>
<p>It's possible to train a DenoiSeg neural network using Python. The required code and instructions can be found <a rel="nofollow" class="external text" href="https://github.com/juglab/DenoiSeg">here</a>. The model that has been trained in Python, can be used in FIJI as well:
</p>
<ol><li> In Python, run this at the end of your training: <code>mode.export_TF()</code>. </li>
<li> Locate the exported model file</li>
<li> Proceed as described in <a href="DenoiSeg.html#Prediction">Prediction</a></li></ol>
<h1><span class="mw-headline" id="Creating_labelings_for_the_training">Creating labelings for the training</span></h1>
<p>There are many possibilities for how to create labelings. But since we get this question a lot, here is how we do it:
</p>
<div class="thumb tright"><div class="thumbinner" style="width:302px;"><a href="./File:Updatesite-labkit.png" class="image"><img alt="" src="_images/e/e1/Updatesite-labkit.png" width="300" height="197" class="thumbimage" /></a>  <div class="thumbcaption"><div class="magnify"><a href="./File:Updatesite-labkit.png" class="internal" title="Enlarge"></a></div>Update site Labkit</div></div></div>
<div class="thumb tright"><div class="thumbinner" style="width:302px;"><a href="./File:Labkit.png" class="image"><img alt="" src="_images/d/da/Labkit.png" width="300" height="225" class="thumbimage" /></a>  <div class="thumbcaption"><div class="magnify"><a href="./File:Labkit.png" class="internal" title="Enlarge"></a></div>Labkit</div></div></div>
<div class="thumb tright"><div class="thumbinner" style="width:276px;"><div class="MediaTransformError" style="width: 274px; height: 0px; display:inline-block;">Error creating thumbnail: Unable to save thumbnail to destination</div>  <div class="thumbcaption"><div class="magnify"><a href="./File:3Dobjectscounter.png" class="internal" title="Enlarge"></a></div>3D Objects counter options</div></div></div>
<ol><li> Install the Labkit update site via <code>Help &gt; Update...</code>, clicking on <code>Manage update sites</code>, and selecting <code>Labkit</code></li>
<li> Restart Fiji</li>
<li> Open the image you want to label</li>
<li> Click <code>Plugins &gt; Segmentation &gt; Labkit</code></li>
<li> Carefully label your data. Use e.g. the pencil tool to outline your labelings and the bucket tool to fill the outlines.</li>
<li> Export the mask by clicking the meny item <code>Labeling &gt; Show Labeling in ImageJ</code></li>
<li> Convert the exported mask (with zero for background and one for foreground into an indexed labelimage
<ol><li> Click <code>Analyze &gt; 3D Objects Counter</code></li>
<li> Make sure to deselect <code>Exclude objects on edges</code></li>
<li> Save the displayed labeling to disk</li></ol></li></ol>

<!-- 
NewPP limit report
Cached time: 20200713064951
Cache expiry: 86400
Dynamic content: false
CPU time usage: 0.036 seconds
Real time usage: 0.038 seconds
Preprocessor visited node count: 47/1000000
Preprocessor generated node count: 52/1000000
Post‐expand include size: 0/2097152 bytes
Template argument size: 0/2097152 bytes
Highest expansion depth: 2/40
Expensive parser function count: 0/3
-->

<!-- 
Transclusion expansion time report (%,ms,calls,template)
100.00%    0.000      1 - -total
-->
</div><div class="printfooter">
Retrieved from "<a dir="ltr" href="index.php?title=DenoiSeg&amp;oldid=45828">http://imagej.net/index.php?title=DenoiSeg&amp;oldid=45828</a>"</div>
							</div>

			<div id="footer">
				<p> This page was last modified on 25 June 2020, at 07:14.</p><ul><li><a href="./ImageJ:Privacy_policy" title="ImageJ:Privacy policy">Privacy policy</a></li><li><a href="./ImageJ:About" class="mw-redirect" title="ImageJ:About">About ImageJ</a></li><li><a href="Imprint" title="Imprint">Imprint</a></li></ul>			</div>

			<div id="catlinks" class="catlinks catlinks-allhidden" data-mw="interface"></div>		</div>

		<div id="bottom-wrap">
			<div id="footer-wrap-inner">
				<div id="ternary" class="footer">
					<ul>
						<li class="widget">
							<img id="logo" src="skins/imagej-128.png" alt="">
						</li>
					</ul>
				</div>
			</div>
		</div>
		<script>(window.RLQ=window.RLQ||[]).push(function(){mw.loader.load(["ext.fancytree","ext.suckerfish","mediawiki.toc","mediawiki.action.view.postEdit","site","mediawiki.user","mediawiki.hidpi","mediawiki.page.ready","mediawiki.searchSuggest","ext.SimpleTooltip"]);});</script><script>(window.RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgBackendResponseTime":210});});</script>
		</body>
		</html>
		