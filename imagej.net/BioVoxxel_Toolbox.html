<!DOCTYPE html>
<html class="client-nojs" lang="en" dir="ltr">
<head>
<meta charset="UTF-8"/>
<title>BioVoxxel Toolbox - ImageJ</title>
<script>document.documentElement.className = document.documentElement.className.replace( /(^|\s)client-nojs(\s|$)/, "$1client-js$2" );</script>
<script>(window.RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgCanonicalNamespace":"","wgCanonicalSpecialPageName":false,"wgNamespaceNumber":0,"wgPageName":"BioVoxxel_Toolbox","wgTitle":"BioVoxxel Toolbox","wgCurRevisionId":42581,"wgRevisionId":42581,"wgArticleId":2060,"wgIsArticle":true,"wgIsRedirect":false,"wgAction":"view","wgUserName":null,"wgUserGroups":["*"],"wgCategories":["Pages using duplicate arguments in template calls","Particle analysis"],"wgBreakFrames":false,"wgPageContentLanguage":"en","wgPageContentModel":"wikitext","wgSeparatorTransformTable":["",""],"wgDigitTransformTable":["",""],"wgDefaultDateFormat":"dmy","wgMonthNames":["","January","February","March","April","May","June","July","August","September","October","November","December"],"wgMonthNamesShort":["","Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec"],"wgRelevantPageName":"BioVoxxel_Toolbox","wgRelevantArticleId":2060,"wgRequestId":"ef1869753e666a8fb60bc372","wgIsProbablyEditable":false,"wgRestrictionEdit":[],"wgRestrictionMove":[],"wgPreferredVariant":"en","fancytree_path":"/extensions/TreeAndMenu/fancytree"});mw.loader.state({"site.styles":"ready","noscript":"ready","user.styles":"ready","user.cssprefs":"ready","user":"ready","user.options":"loading","user.tokens":"loading","mediawiki.legacy.shared":"ready","mediawiki.legacy.commonPrint":"ready","mediawiki.sectionAnchor":"ready","skins.erudite":"ready"});mw.loader.implement("user.options@0j3lz3q",function($,jQuery,require,module){mw.user.options.set({"variant":"en"});});mw.loader.implement("user.tokens@1ku9xth",function ( $, jQuery, require, module ) {
mw.user.tokens.set({"editToken":"+\\","patrolToken":"+\\","watchToken":"+\\","csrfToken":"+\\"});/*@nomin*/;

});mw.loader.load(["mediawiki.page.startup"]);});</script>
<link rel="stylesheet" href="load.php%3Fdebug=false&amp;lang=en&amp;modules=mediawiki.legacy.commonPrint%252Cshared%257Cmediawiki.sectionAnchor%257Cskins.erudite&amp;only=styles&amp;skin=erudite.css"/>
<script async="" src="load.php%3Fdebug=false&amp;lang=en&amp;modules=startup&amp;only=scripts&amp;skin=erudite"></script>
<link rel="stylesheet" href="extensions/TreeAndMenu/fancytree/fancytree.css"/><link rel="stylesheet" href="extensions/TreeAndMenu/suckerfish/suckerfish.css"/>
<meta name="ResourceLoaderDynamicStyles" content=""/>
<link rel="stylesheet" href="load.php%3Fdebug=false&amp;lang=en&amp;modules=site.styles&amp;only=styles&amp;skin=erudite.css"/>
<meta name="generator" content="MediaWiki 1.28.0"/>
<meta name="description" content="You can setup an automatic update for the BioVoxxel Toolbox. Just run the Updater ( Help &amp;#160;&amp;#8250;  Update...) and switch in the main window to 'Advanced mode'. Then click on 'Manage update sites'. Here you simply need to activate the &quot;BioVoxxel&quot;. See here how to follow an update site follow an update site"/>
<link rel="shortcut icon" href="skins/ij2.ico"/>
	<meta property="og:type" content="article"/>

	<meta property="og:site_name" content="ImageJ"/>

	<meta property="og:title" content="BioVoxxel Toolbox"/>

	<meta property="og:description" content="You can setup an automatic update for the BioVoxxel Toolbox. Just run the Updater ( Help &amp;#160;&amp;#8250;  Update...) and switch in the main window to 'Advanced mode'. Then click on 'Manage update sites'. Here you simply need to activate the &quot;BioVoxxel&quot;. See here how to follow an update site follow an update site"/>


<meta name="viewport" content="width=device-width, initial-scale=1" />
</head>
<body class="mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject page-BioVoxxel_Toolbox rootpage-BioVoxxel_Toolbox skin-erudite action-view">
		<div class="mw-jump">
			<a href="BioVoxxel_Toolbox.html#bodyContent">Skip to content</a>, 			<a href="BioVoxxel_Toolbox.html#search">Skip to search</a>
		</div>

		<div id="top-wrap" role="banner">
			<h1><a href="Welcome" title="ImageJ" rel="home">ImageJ</a></h1>
			<div id="tagline">From ImageJ</div>

			<a id="menubutton" href="BioVoxxel_Toolbox.html#menu">Menu</a>
			<div id="nav" role="navigation">
			<ul id='menu'>
<li id="menu-item-n-About"><a href="ImageJ">About</a></li>
<li id="menu-item-n-Downloads"><a href="Downloads">Downloads</a></li>
<li id="menu-item-n-Learn"><a href="Learn">Learn</a></li>
<li id="menu-item-n-Develop"><a href="Development">Develop</a></li>
<li id="menu-item-n-News"><a href="News">News</a></li>
<li id="menu-item-n-Events"><a href="Events">Events</a></li>
<li id="menu-item-n-Help"><a href="Help">Help</a></li>
</ul>
			</div>
		</div>

		<div id="mw-js-message"></div>
		
		<div id="main" role="main">
			<div id="nav-meta">
			<span id="ca-nstab-main" class="selected"><a href="BioVoxxel_Toolbox" title="View the content page [c]" accesskey="c">Page</a></span><span class="meta-sep">|</span><span id="ca-talk" class="new"><a href="index.php?title=Talk:BioVoxxel_Toolbox&amp;action=edit&amp;redlink=1" rel="discussion" title="Discussion about the content page [t]" accesskey="t">Discussion</a></span><span class="meta-sep">|</span><span id="ca-viewsource"><a href="index.php?title=BioVoxxel_Toolbox&amp;action=edit" title="This page is protected.&#10;You can view its source [e]" accesskey="e">View source</a></span><span class="meta-sep">|</span><span id="ca-history"><a href="index.php?title=BioVoxxel_Toolbox&amp;action=history" title="Past revisions of this page [h]" accesskey="h">History</a></span><span class="meta-sep">|</span>			</div>

			<div id="bodyContent">
				<h1>BioVoxxel Toolbox</h1>
				
				<div id="mw-content-text" lang="en" dir="ltr" class="mw-content-ltr"><table class="infobox" cellspacing="5" style="max-width: 31em; font-size: 90%; text-align: left; float: right; border: 1px solid #a0a0a0;">
<tr>
<th colspan="2" style="text-align: center; font-size: 130%;"> <div style="float: left"></div>BioVoxxel Toolbox (ImageJ / Fiji)<div style="clear: left;"></div>
</th></tr>
<tr>
<th> Author
</th>
<td> <a href="User:BioVoxxel" class="mw-redirect" title="User:BioVoxxel">Jan Brocher</a>
</td></tr>
<tr>
<th> Update site
</th>
<td> <a href="Following_an_update_site" title="Following an update site">BioVoxxel</a>
</td></tr>



<tr>
<th> Maintainer
</th>
<td> <a href="User:BioVoxxel" class="mw-redirect" title="User:BioVoxxel">Jan Brocher</a>
</td></tr>


<tr>
<th> Source
</th>
<td> <a rel="nofollow" class="external text" href="https://github.com/biovoxxel/BioVoxxel-Toolbox">GitHub</a>
</td></tr>
<tr>
<th> Initial release
</th>
<td> 2014
</td></tr>
<tr>
<th> Latest version
</th>
<td> 12. February 2020
</td></tr>
<tr>
<th> Development status
</th>
<td> stable (active maintainance)
</td></tr>
<tr>
<th> Category
</th>
<td> <a href="Category:Particle_analysis" title="Category:Particle analysis">Particle analysis</a>, <a href="Category:Binary" title="Category:Binary">Binary</a>, <a href="Category:Filtering" title="Category:Filtering">Filtering</a>
</td></tr>
<tr>
<th> Website
</th>
<td> <a rel="nofollow" class="external text" href="http://www.biovoxxel.de/index.html">www.biovoxxel.de</a>
</td></tr>
</table>
<p>You can setup an automatic update for the BioVoxxel Toolbox. Just run the <a href="Updater" title="Updater">Updater</a> (<span><em><span style="border-bottom:1px dotted #ccc;"> Help </span>&#160;&#8250; <span style="border-bottom:1px dotted #ccc;"> Update...</span></em></span>) and switch in the main window to 'Advanced mode'. Then click on 'Manage update sites'. Here you simply need to activate the "BioVoxxel". See here how to follow an update site <a rel="nofollow" class="external text" href="Following_an_update_site">follow an update site</a>
</p><p>You will find all functions of the BioVoxxel Toolbox under the icon of the green BioVoxxel cube after selecting BioVoxxel Toolbox from the More Tools Icon (last Icon in the ImageJ/Fiji Icon list with the double arrow).
</p>
<hr />
<div id="toc" class="toc"><div id="toctitle"><h2>Contents</h2></div>
<ul>
<li class="toclevel-1 tocsection-1"><a href="BioVoxxel_Toolbox.html#Extended_Particle_Analyzer"><span class="tocnumber">1</span> <span class="toctext">Extended Particle Analyzer</span></a></li>
<li class="toclevel-1 tocsection-2"><a href="BioVoxxel_Toolbox.html#Field-of-view_measure_correction"><span class="tocnumber">2</span> <span class="toctext">Field-of-view measure correction</span></a></li>
<li class="toclevel-1 tocsection-3"><a href="BioVoxxel_Toolbox.html#Shape_Descriptor_Maps"><span class="tocnumber">3</span> <span class="toctext">Shape Descriptor Maps</span></a></li>
<li class="toclevel-1 tocsection-4"><a href="BioVoxxel_Toolbox.html#Binary_Feature_Extractor"><span class="tocnumber">4</span> <span class="toctext">Binary Feature Extractor</span></a></li>
<li class="toclevel-1 tocsection-5"><a href="BioVoxxel_Toolbox.html#Speckle_Inspector"><span class="tocnumber">5</span> <span class="toctext">Speckle Inspector</span></a></li>
<li class="toclevel-1 tocsection-6"><a href="BioVoxxel_Toolbox.html#Watershed_Irregular_Features"><span class="tocnumber">6</span> <span class="toctext">Watershed Irregular Features</span></a></li>
<li class="toclevel-1 tocsection-7"><a href="BioVoxxel_Toolbox.html#EDM_Binary_Operations"><span class="tocnumber">7</span> <span class="toctext">EDM Binary Operations</span></a></li>
<li class="toclevel-1 tocsection-8"><a href="BioVoxxel_Toolbox.html#Auto_Binary_Masking"><span class="tocnumber">8</span> <span class="toctext">Auto Binary Masking</span></a></li>
<li class="toclevel-1 tocsection-9"><a href="BioVoxxel_Toolbox.html#Threshold_Check"><span class="tocnumber">9</span> <span class="toctext"><b>Threshold Check</b></span></a></li>
<li class="toclevel-1 tocsection-10"><a href="BioVoxxel_Toolbox.html#Filter_Check"><span class="tocnumber">10</span> <span class="toctext">Filter Check</span></a></li>
<li class="toclevel-1 tocsection-11"><a href="BioVoxxel_Toolbox.html#Flat-field_and_Pseudo_flat-field_correction"><span class="tocnumber">11</span> <span class="toctext">Flat-field and Pseudo flat-field correction</span></a></li>
<li class="toclevel-1 tocsection-12"><a href="BioVoxxel_Toolbox.html#Convoluted_Background_Subtraction"><span class="tocnumber">12</span> <span class="toctext">Convoluted Background Subtraction</span></a></li>
<li class="toclevel-1 tocsection-13"><a href="BioVoxxel_Toolbox.html#Scaled_Intensity_Plot"><span class="tocnumber">13</span> <span class="toctext">Scaled Intensity Plot</span></a></li>
<li class="toclevel-1 tocsection-14"><a href="BioVoxxel_Toolbox.html#Stack_Line_Plots"><span class="tocnumber">14</span> <span class="toctext">Stack Line Plots</span></a></li>
<li class="toclevel-1 tocsection-15"><a href="BioVoxxel_Toolbox.html#Adaptive_Filter"><span class="tocnumber">15</span> <span class="toctext">Adaptive Filter</span></a></li>
<li class="toclevel-1 tocsection-16"><a href="BioVoxxel_Toolbox.html#Recursive_Filters"><span class="tocnumber">16</span> <span class="toctext">Recursive Filters</span></a></li>
<li class="toclevel-1 tocsection-17"><a href="BioVoxxel_Toolbox.html#Difference_of_Gaussian_and_Difference_from_Median"><span class="tocnumber">17</span> <span class="toctext">Difference of Gaussian and Difference from Median</span></a></li>
<li class="toclevel-1 tocsection-18"><a href="BioVoxxel_Toolbox.html#Hyperstack_Color_Coding"><span class="tocnumber">18</span> <span class="toctext">Hyperstack Color Coding</span></a></li>
<li class="toclevel-1 tocsection-19"><a href="BioVoxxel_Toolbox.html#Neighbor_Analysis"><span class="tocnumber">19</span> <span class="toctext">Neighbor Analysis</span></a></li>
<li class="toclevel-1 tocsection-20"><a href="BioVoxxel_Toolbox.html#2D_Particle_Distribution"><span class="tocnumber">20</span> <span class="toctext">2D Particle Distribution</span></a></li>
<li class="toclevel-1 tocsection-21"><a href="BioVoxxel_Toolbox.html#SSIDC_Cluster_Indicator"><span class="tocnumber">21</span> <span class="toctext">SSIDC Cluster Indicator</span></a></li>
<li class="toclevel-1 tocsection-22"><a href="BioVoxxel_Toolbox.html#Cluster_Indicator"><span class="tocnumber">22</span> <span class="toctext">Cluster Indicator</span></a></li>
<li class="toclevel-1 tocsection-23"><a href="BioVoxxel_Toolbox.html#Skeleton_Length_.28corrected.29"><span class="tocnumber">23</span> <span class="toctext">Skeleton Length (corrected)</span></a></li>
<li class="toclevel-1 tocsection-24"><a href="BioVoxxel_Toolbox.html#Nearest_Neighbor_Indicator_.28Separate_Tool.29"><span class="tocnumber">24</span> <span class="toctext">Nearest Neighbor Indicator (Separate Tool)</span></a></li>
<li class="toclevel-1 tocsection-25"><a href="BioVoxxel_Toolbox.html#Gaussian_weighted_Median_filter"><span class="tocnumber">25</span> <span class="toctext">Gaussian weighted Median filter</span></a></li>
<li class="toclevel-1 tocsection-26"><a href="BioVoxxel_Toolbox.html#Enhance_True_Color_Contrast"><span class="tocnumber">26</span> <span class="toctext">Enhance True Color Contrast</span></a></li>
<li class="toclevel-1 tocsection-27"><a href="BioVoxxel_Toolbox.html#Mode_and_Differential_Limited_Mean_Binarization"><span class="tocnumber">27</span> <span class="toctext">Mode and Differential Limited Mean Binarization</span></a></li>
</ul>
</div>

<h1><span class="mw-headline" id="Extended_Particle_Analyzer">Extended Particle Analyzer</span></h1>
<p>Purpose: The "Extended Particle Analyzer" is based on the ImageJ "Analyze Particles..." command. It enables the user to further restrict the analysis on particles according to many more parameter spezifications of shape descriptors and angle orientations. Thus, setting minimal and maximal exclusion ranges of different parameters enables to extract particles from a binary image. The output types are the same as for the <span><em><span style="border-bottom:1px dotted #ccc;"> Analyze </span>&#160;&#8250; <span style="border-bottom:1px dotted #ccc;"> Analyze Particles</span></em></span>.
</p><p>Example: If you want to extract/analyze only particles with a certain Feret's Angle or exclude elongated structures using the aspect ratio (AR) or circilarity you can specify so in the initial dialog box.
</p><p><a href="File:ExtendedParticleAnalyzer_v2.png" class="image"><img alt="ExtendedParticleAnalyzer v2.png" src="_images/2/27/ExtendedParticleAnalyzer_v2.png" width="750" height="563" /></a>
</p><p>How to: Key in minimal and maximal exclusion values connected with a hyphen. You can use integers as well as numbers containing decimal places. "Redirect" redirects the analysis to a grayscale image which enables to analyze skewness, kurtosis as well as the new measure coefficient of variance (cov). The option "Keep borders (correction)" eliminates particles from 2 edges and keeps particles touching the two borders of choice. This corrects the particle count for edge touching particles.
</p><p>Tipp: use the "Shape Descriptor Maps" macro to figure out possible cut-off value combinations for your analysis which you can then use in the Extended Particle Analyzer.
</p><p>Shape descriptors which are not available under "Analyze Particles..." in IJ or Fiji so far are:
</p><p>Extent = [net area of feature] / [bounding rectangle]
</p><p>Compactness = [sqrt(4 * area / PI)] / [major axis]
</p><p>Feret's AR = [maximum caliper diameter] / [minimum caliper diameter]
</p><p>Coefficient of variance (CoV) = [intensity standard deviation] / [intensity mean]
</p><p><br />
<b>The new version from 11th February 2018 (included from BioVoxxel_Plugins-2.0.1) on contains 2 checkboxes which enable the choice between pixel and calibrated units in images which are spatially calibrated. The checkbox "Pixel units" is equivalent to the checkbox with the same label in the standard IJ Analyze Particels... function and uses pixels instead of calibrated units to limit the analysis with the respective parameters. The checkbox "output in pixels" gives the option to separately choose if the results table should be in specific units or pixels (depending on the image calibration). Older Macros should still run, while the keyword "pixel" needs to be shifted before the definition of the area parameter.</b>
</p><p><br />
Form: plugin (recordable, <i>uses smart recording --&gt; records only fields which have been changed by the user while recording. Default entries will not be recorded. It is already sufficient to cut a zero after the comma without changing the actual parameter value to make the recorder recognize that the entry should be recorded!</i>) 
</p><p>Status: Maintenance active
</p><p>Suggestions are welcome!
</p>
<hr />
<h1><span class="mw-headline" id="Field-of-view_measure_correction">Field-of-view measure correction</span></h1>
<p>Purpose: The macro eliminates all particles in a binary image which touch the edges, then counts the remaining particles and corrects for the counting and the mean area bias due to the edge intersection using the following formula:
</p><p>count correction factor = (ImgWidth * ImgHeight) / ((ImgWidth-BBWidth) * (ImgHeight-BBHeight))
</p><p>with "ImgWidth" and "ImgHeight" as the size of the analyzed image and "BBWidth" and "BBHeight" as the bounding box dimensions of each particle. This is recommended as a correction for the bias when measuring features in a field of view because bigger particles are more likely to touch the edges of the field of view and thus their area is are underestimated. This underestimation is proportionate to the particle size. (according to J. Russ, The Image Processing Handbook, 2010, 6th Edition).
</p><p>How to: only works on individual 8-bit binary images.
</p><p>Form: macro
</p><p>Status: maintenance active
</p><p>Future: Suggestions are welcome!
</p>
<hr />
<h1><span class="mw-headline" id="Shape_Descriptor_Maps">Shape Descriptor Maps</span></h1>
<p>Purpose: Shape descriptors of the particles in an 8-bit binary image will be color coded (smallest to biggest values) and are shown in a stack containing the original image in the first slice and the "shape descriptor maps" in the consecutive ones. The respective shape descriptors are indicated in each slice. A calibration bar (LUT can be selected in the setup) enables easier overview and interpretation. The highest descriptor values can also be displayd as an orientation. 
Since version 0.6, when "interactive plots" is enabled, the user can simply click on one of the slices in the color coded output stack to receive a plot of the respective size sorted shape descriptor. <b>To finally abort the macro when interactive plots is active "Esc" needs to be pressed</b>. 
</p><p>The interactive plots enable to hover over the plot surface or retreiving the plot list to determine potential exclusion parameters which consecutively can be used with the "Advanced Particle Analyzer".
</p><p>This macro helps to visually identify features in images according to their shape properties. Additionally, you can also use the color coded images for consecutive color thresholding after transfering them into RGB mode to extract specific features from the images, according to their coding color.
</p><p>How to: Select analysis modes and start.
</p><p><a href="File:ShapeDescriptorMaps.png" class="image"><img alt="ShapeDescriptorMaps.png" src="_images/5/5b/ShapeDescriptorMaps.png" width="750" height="442" /></a>
</p><p>Form: macro
</p><p>Status: Maintenance active
</p><p>Future: Suggestions are welcome!
</p>
<hr />
<h1><span class="mw-headline" id="Binary_Feature_Extractor">Binary Feature Extractor</span></h1>
<p>Purpose: The "Feature Extractor" is aimed to select isolate specific features in a binary image by other binary particles as selectors which are located completely inside the features or overlap partially with those. It additionally allows also to get a visual combination of extracted features and selectors (combining those images by using a boolean OR function). The idea for the feature extractor is taken from J. Russ "The Image Processing Handbook" 6th Edition.
</p><p>Example: A specific nuclear fluorescent staining is thresholded as the selector while the complete cells are thresholded as the features to be extracted.
</p><p>How to: First, specify the images containing on the one hand the objects to extract and on the other hand the selectors (e.g. marker staining, cell masks) which defines the objects that should be extracted. The plugin then extracts the features which overlap with the selector. The "Overlap in percent" option enables to define a minimal overlap fraction (in percent) of the selector area with the object area (in exactly this sequence). The object is only extracted if the overlap is equal or bigger than the defined minimal overlap.
Finally, you can define to show the count of objects, selectors and extracted features as well as display the individual results tables for the three different images (This is equal to run the "Analyze Particles..." on each of the images.
</p><p><a href="File:FeatureExtractor1.png" class="image"><img alt="FeatureExtractor1.png" src="_images/2/26/FeatureExtractor1.png" width="750" height="492" /></a>
</p><p>Status: plugin v1.0, can be run from the BioVoxxel Toolbox Menu, maintenance active
</p><p>Future: Further suggestions are welcome!
</p>
<hr />
<h1><span class="mw-headline" id="Speckle_Inspector">Speckle Inspector</span></h1>
<p>Purpose: The "Speckle Inspector" is able to identify bigger features by the number of containing smaller features/speckles.
</p><p>How to: In the setup dialog the user can enter the 2 images to be analyzed as well as lower and upper limits of speckle numbers, speckle sizes, object size and object circularity to determine characteristics which include/exclude speckles and features from the analysis according to the entered parameters.
</p><p><a href="File:SpeckleInspector1.png" class="image"><img alt="SpeckleInspector1.png" src="_images/9/99/SpeckleInspector1.png" width="1200" height="568" /></a>
</p><p>The macro gives different outputs. The optical output is an color-coded image, where positive features (lying inbetween the determined minimum and maximum parameters) are colord in magenta, features containing less than the specified minimum speckle numbers are colored in blue and features containing more than the specified maximum speckle numbers are colored in green. In the same image the features are numbered to identify them in the respective speckle list as well as the ROI manager. Furthermore, they contain the number of "speckles" per feature in brackets. The second output are all feature selection ROIs in the ImageJ/Fiji ROI manager. Moreover a list of all features and respective speckle numbers is given if "show speckle list" was ticked. The "statistics log" window depicts an analysis of the features showing overall numbers of features and speckles as well as the numbers for the features lying below, inbetween, and above the thresholds.
You can also choose if you want to see the RoiManager for the objects rois to further analyze the original image.
"individual roi analysis" returns a results table which contains the analyzed particles inside each roi (the latter is indicated in the results "Label" column).
</p><p>New: now the "Speckle Inspector" comes as recordable plugin
</p><p>Form: plugin, recordable
</p><p>Status: maintenance active
</p><p>Future: suggestions are welcome!
</p>
<hr />
<h1><span class="mw-headline" id="Watershed_Irregular_Features">Watershed Irregular Features</span></h1>
<p>Purpose: The standard watershed algorithm in ImageJ is very usefull to separate connected, roughly circular structures. Nevertheless, it gets into trouble while separating irregular (non-ellipsoid like) structures. The Irregular Watershed enables the user to separate also irregular shaped structures to a certain extend.
</p><p><a href="File:Watershed_Irregular_Features.png" class="image"><img alt="Watershed Irregular Features.png" src="_images/6/6a/Watershed_Irregular_Features.png" width="770" height="681" /></a>
</p><p>How to: The user needs to specify one of two parameters:
</p><p>1.) Erosion cycle number: The erosion cycles to be used for the separation algorithm. "0" prevents watershedding. Since increasing numbers use a decreasing size of selector for the separations to be skipped, a too high number might result in unwanted separation in the peripheral regions of the features. Increasing numbers lead to results closer to the standard IJ watershed. The separation only works in the 2D space at the moment and has its limitations when the connecting "bridges" between the features are too broad (as true for the normal watershed algorithm).
</p><p>2.) Convexity threshold: if this value is above "0" the erosion cycle number is ignored. All objects which have a convexity bigger than the threshold are kept in the image and eroded. If eroded objects coincide with separation lines of the original watershed, those remain in the image and are not used to separate the objects. The sequence of convexity thresholding and consecutive erosion is repeated until there is no object remaining with a convexity above the threshold or the image cannot be eroded any further.
</p><p>3.) Separator size: the separator size describes the length of the one-pixel line separating connected particles. Thus, the user can specifically choose a size range in which the particle connections should be separated. Additionally, the option "exclude" enables to exclude the specified sizes and separate only connections which are smaller than the lower and bigger than the upper limit.
</p><p>Form: plugin, recordable
</p><p>Status: maintenance active
</p><p>Thanks to Thorsten Wagner which provided the ij-blobs library as basis and the idea to integrate convexity as a second parameter to make the function scale invariant and more flexible. 
</p><p>Future: Suggestions are welcome!
</p>
<hr />
<h1><span class="mw-headline" id="EDM_Binary_Operations">EDM Binary Operations</span></h1>
<p>Purpose: The standard binary erosion and dilation suffers from the artefact that under higher iteration cycles the binary structures get irregularly deformed (see image below, second column). The EDM based methods for erosion and dilation prevent these artifacts. The method is using thresholding on a 8-bit euclidean distance map of the original image to facilitate binary erosion, dilation, opening and closing.
</p><p><a href="File:EDMErosionDilation.png" class="image"><img alt="EDMErosionDilation.png" src="_images/9/9b/EDMErosionDilation.png" width="600" height="450" /></a>
</p><p>How to: The number of iterations determines how often the chosen function will be applied to the image.
</p><p>Form: plugin (with preview, recordable)
</p><p>Status: works on stacks now, maintenance active
</p><p>Future: suggestions are welcome!
</p>
<hr />
<h1><span class="mw-headline" id="Auto_Binary_Masking">Auto Binary Masking</span></h1>
<p>Purpose: The macro enables to mask images with their thresholded binary counterparts. Works with 2D images and 3D stacks.
</p><p>How to: Original and binary mask images need to be identified from the drop-down menu and the user needs to specify if black or white areas in the binary image should be transparent. The output image shows the masked features from the original image.
</p><p>Form: macro
</p><p>Status: maintenance active
</p><p>Future: Will be implemented for hyperstacks. Suggestions are welcome!
</p>
<hr />
<h1><span class="mw-headline" id="Threshold_Check"><b>Threshold Check</b></span></h1>
<p>Purpose: The "Threshold Check" should simply provide a help in deciding which of the 16 <a href="Auto_Threshold" title="Auto Threshold">Auto Threshold</a> and the 9 <a href="Auto_Local_Threshold" title="Auto Local Threshold">Auto Local Threshold</a> outputs from the respective plugins results in the potentially best binary image outcome. This is not an absolute measure but should rather assist in the decision for the application of one specific auto threshold algorithm in non-obvious cases. In the new version you can choose additionally to quantify the quality of the thresholding.
</p><p>How to: The user needs to first select the image the in which the thresholds should be checked (including all the pre-processing you want/need to apply). Be aware to also specify if you are thresholding bright or dark features in the first checkbox! You can also choose to ignore black or white pixels from the threshold calculations (as in the normal AutoThreshold dialog). Furthermore, you can choose to include also the 9 Auto Local Thresholds with the respective parameters (for further reading check out: Auto Local Thresholds. Finally, you can include a quantification of the results and choose if you want to have an overview montage in addition to the normal stack output. Thresholds are indicated in the upper left corner of the images for better identification.
</p><p>Output interpretation: You will get a stack with each thresholding method represented in a single stack slice. The following colors should help in interpreting the thresholding result:
</p><p><a href="File:ThresholdCheck.png" class="image"><img alt="ThresholdCheck.png" src="_images/4/40/ThresholdCheck.png" width="770" height="502" /></a>
</p><p><b>blue</b> = this is thresholded as background and also represents black or very dark areas in the original image, thus most likely beeing really background.
</p><p><b>cyan</b> = these areas have a certain brightness level in the original image but are not recognized by the respective tresholding algorithm, hence might point out a underestimation of features by the threshold.
</p><p><b>orange/yellow</b> = these are features standing out from the background in the original image (orange=medium intensity; yellow=high intensity) which are recognized by the thresholding algorithm as foreground features and thus most likely represent features of interest (depending on the image context and quality).
</p><p><b>red/dark orange</b> = these areas have a very low brightness (or are black) in the original image but are thresholded as foreground and therefore most likely represent an overestimation by the threshold.
</p><p>Caution: Interpretation should be done with care and in context to the original image and imaging settings. This macro is thought to assist in the decision for choosing a good thresholding method. It is no absolute measure for thresholding quality!
</p><p>Quantification: The Quantification is shown in a results window in&#160;%Area. The threshold names are followed by either (under), (positive) or (over). This referres to the following:
</p><p><b>- under:</b> the percentage of pixels in comparison to the complete image which seem to be under-thresholded (displayed in cyan)
</p><p><b>- positive:</b> the percentage of pixels inside the thresholded region which seem to be well thresholded (displayed in bright orange and yellow)
</p><p><b>- over:</b> the percentage (100-positive) of pixels inside the thresholded region which seem to be over-thresholded (displayed in red)
</p><p>The macro finally suggests thresholds which perform best in respect to the reference point selection. This suggestion depends on the reference point selection and always needs to be compared to the color-coded visual output as well as to the necessities for the following analysis.
</p><p>Potential issues: If the user does not correctly define if he/she is looking for bright or dark objects the output will be incorrectly determined.
</p><p><b>Publication:</b> <a rel="nofollow" class="external text" href="http://www.cscjournals.org/library/manuscriptinfo.php?mc=IJIP-829">Qualitative and Quantitative Evaluation of Two New Histogram Limiting Binarization Algorithms</a>.
J. Brocher, Int. J. Image Process. 8(2), 2014 pp. 30-48
</p><p>Form: macro (plugin currently under development)
</p><p>Status: v2.2 (performance improved), maintenance active
</p><p>Future: Suggestions are welcome!
</p>
<hr />
<h1><span class="mw-headline" id="Filter_Check">Filter Check</span></h1>
<p>Purpose: This plugin enables you to test a certain range of radii of a specified image filter in one step. This shoud facilitate a better decision on a suitable filter for your processing purpose.
</p><p>How to: Choose a filter method from the drop down menu, key in a starting and an end radius. The image will be filtered in individual integer steps between the start and stop radius and presented in an image stack containing all the filtered images. The filter can also be applied to only a ROI. This is recommended for filters which are cost intensive, like the "Gaussian Weighted Median". 
The parameter setting is only needed for the "Bilateral Filter" (range radius) , "Mean Shift Filter" (Color Distance) and the "Linear Kuwahara" (line length).
</p><p><a href="File:Filter_Check.png" class="image"><img alt="Filter Check.png" src="_images/1/14/Filter_Check.png" width="750" height="309" /></a>
</p><p>Form: plugin
</p><p>Status: maintenance active
</p><p>Future: potentially additional filters will be added
</p>
<hr />
<h1><span class="mw-headline" id="Flat-field_and_Pseudo_flat-field_correction">Flat-field and Pseudo flat-field correction</span></h1>
<p>Purpose: The macro enables to "subtract" background due to inequal lighting from grayscale and true color images. It either uses a previously taken flat-field image (&gt;Flat-field correction) or creates an artificial flat-field image (&gt;Pseudo flat-field correction) from the selected original image. For true color images this is done using the brightness channel of an HSB stack. The original image (brightness channel for true color images) is divided by the flat-field image and the brightness is normalized using the mean intensity of the original image.
</p><p>How to: You need either choose the two images in the "Flat-field" version or specify a gaussian blurring radius for the "Pseudo flat-field correction" in a way to eliminate specific feature appearance but to keep the difference in shading/lighting. Therefore, rather big radii (sigma) are needed (potentially between 40-150, but this depends on image and feature size).
</p><p>Remark: The pseudo flat field correction menu command links to the plugin with the same name under <span><em><span style="border-bottom:1px dotted #ccc;"> Plugins </span>&#160;&#8250; <span style="border-bottom:1px dotted #ccc;"> BioVoxxel</span></em></span> (necessary to additionally download from the BioVoxxel update site together with the Toolbox). 
</p><p>Advantage of the Pseudo flat field correction: This is now recordable and works with stacks. Thus, time-lapse movies e.g. from a brightfield microscope can be completely corrected for unequal lighting according to the individual differences in each frame. The blurring is visualized on the currently active frame to be able to sufficiently eliminate structural information.
</p><p><br />
Form of Flat-field correction: macro
</p><p>form of Pseudo Flat-field correction: plugin
</p><p>Status: maintenance active, problems with specific stacks (fill be addressed soon)
</p><p>Future: suggestions are welcome!
</p>
<hr />
<h1><span class="mw-headline" id="Convoluted_Background_Subtraction">Convoluted Background Subtraction</span></h1>
<p>Purpose: This tool enables to subtract the background from an image by creating a convoluted copy of the original image and subtracting the filtered image from it. 
This background subtraction method should facilitate consecutive feature extraction and is not suitable prior to intensity analyses!
</p><p>How to: The user can choose between Gaussian, Median and Mean convolution filters and key in the respective filter radius (or sigma for the Gaussian Blur). The preview option directly gives a possiblity to compare the results of the background subtraction.
The radius for the Gaussian method can be chosen around the biggest feature diameter (as for the rolling ball method). The median and mean methos might need bigger values to avoid elimination of bigger features!
</p><p>Method: The convoluted images are directly subtracted from the original with exception of the median filtered one. The latter additionally receives a grayscale dilation by application of a maximum filter with the factor (1.5*(radius/10)). This should reduce artifacts around object borders.
</p><p><a href="File:Convoluted_Background_Subtraction.png" class="image"><img alt="Convoluted Background Subtraction.png" src="_images/e/e4/Convoluted_Background_Subtraction.png" width="750" height="518" /></a>
</p><p>Distribution: plugin, recordable
</p><p>Status: maintenance active!
</p><p>Future: suggestions are welcome!
</p>
<hr />
<h1><span class="mw-headline" id="Scaled_Intensity_Plot">Scaled Intensity Plot</span></h1>
<p>Purpose: The tool creates a intensity plot along any kind of lines as well as from rectangular selections (as does <span><em><span style="border-bottom:1px dotted #ccc;"> Analyze </span>&#160;&#8250; <span style="border-bottom:1px dotted #ccc;"> Plot Profile</span></em></span>) but with the initial possibility to influence the displayed intensity scale. This enables to create plots which can be overlayed by choosing "add to existing plot". In the case of a rectangular selection it can be chosen if the plotting direction should be horizontal or vertical. The intensities along the other direction are then averaged. Additionally, the color and look of the plot line can be chosen.
This should enable to better compare intensity plots from different images or selections which is only possible if they have the same scaling. The latter is done in unscaled units (pixels). 
If a new plot line is added to an existing plot the choice "Draw grid lines" is either ignored or forced depending on how the destination plot was created using the same tool. 
</p><p><a href="File:ScaledIntensityPlots.png" class="image"><img alt="ScaledIntensityPlots.png" src="_images/2/22/ScaledIntensityPlots.png" width="750" height="563" /></a>
</p><p>Form: macro
</p><p>Status: deprecated
</p>
<hr />
<h1><span class="mw-headline" id="Stack_Line_Plots">Stack Line Plots</span></h1>
<p>Purpose: The stack line plot enables to make line plots over a complete stack of images. 
</p><p>How To: The line can be either straight, freehand or segmented and needs to be drawn beforehand. If the input image is a hyperstack the user can choose to plot over the z-slice or the t-frame range. In such a case the intensities of the active channel are taken for the plot. The macro automatically creates a stack of plots along the line selection with the upper intensity limit set at  the highest intensity occurring along the line over all images. If the [Shift] key is held down before and while going to &gt;BioVoxxel Icon &gt;Stack Line Plots the limit is set to 255 for  8-bit images and 65535 for 16-bit images
</p><p><a href="File:StackLinePlots.png" class="image"><img alt="StackLinePlots.png" src="_images/c/ce/StackLinePlots.png" width="750" height="400" /></a>
</p><p>Form: macro
</p><p>Status: deprecated
</p>
<hr />
<h1><span class="mw-headline" id="Adaptive_Filter">Adaptive Filter</span></h1>
<p>(separate plugin under <span><em><span style="border-bottom:1px dotted #ccc;"> Plugins </span>&#160;&#8250; <span style="border-bottom:1px dotted #ccc;"> BioVoxxel</span></em></span>)
</p><p>Purpose/How to: This filter allows the choice between two basic filter modes (<i>median</i> and <i>mean</i>). The filter <i>Radius</i> defines the size of a square kernel (so actually not really a radius but to keep the entries intuitively similar to other filters in Fiji this label was chosen).
</p><p>The <i>Shape</i> option enables a basic pre-selection of pixels from the kernel neighborhood to be taken into account for filtering. After pressing 'Ok', a checkbox grid will be displayed from which the user can adjust the selected pixels for the final filter according to the filtering needs (e.g. to remove power lines in a photograph).
</p><p><i>Tolerance</i> sets a threshold which will change intensity values after filtering only for those pixels where the difference to the original intensity is at least as high as the tolerance (0.2 = 20%). This enables to remove extreme outliers from the image while preserving the original pixel values in image areas without such outliers (at least for shot noise).
</p><p>In the image below the upper pannels show the original photograph and a version with artificial shot noise added. The lower pannels depict the noisy image after a median filter (radius=2) or after the Adaptive Filter (radius = 2 and tolerance set to 0.2) using a circle-like kernel.
</p>
<div class="MediaTransformError" style="width: 680px; height: 0px; display:inline-block;">Error creating thumbnail: Unable to save thumbnail to destination</div>
<p>Output: The filter will be applied directly on the input image. It is undoable (by pressing [z]).
</p><p>Limitation: So far, the filter is only applicable on 8-bit and 16-bit single images.
</p><p>Installation: Part of the BioVoxxel update site in Fiji and can be found under <span><em><span style="border-bottom:1px dotted #ccc;"> Plugins </span>&#160;&#8250; <span style="border-bottom:1px dotted #ccc;"> BioVoxxel</span></em></span>
</p><p>Form: plugin, recording still not fully functional!!!
</p><p>Status: maintenance active
</p><p>Future: Will be adjusted für 32-bit float-type images as well as RGB images and stacks. Suggestions are welcome!
</p>
<hr />
<h1><span class="mw-headline" id="Recursive_Filters">Recursive Filters</span></h1>
<p>Purpose: The recursive filters plugin allows to repetitively apply one of the three basic image filters (Gaussian Blur, Mean, Median) with small radii (max = 3) by adjusting the iteration. The previously filtered image will then be taken as basis for the next image filtering
</p><p>The maximum iteration can be set by the user up to 500 times but will be stopped if two consecutive filtered images do not show any further difference.
</p><p><a href="File:RecursiveFilters01.png" class="image"><img alt="RecursiveFilters01.png" src="_images/8/8f/RecursiveFilters01.png" width="500" height="535" /></a>
</p><p>Form: recordable plugin
</p><p>Status: maintenance active
</p>
<hr />
<h1><span class="mw-headline" id="Difference_of_Gaussian_and_Difference_from_Median">Difference of Gaussian and Difference from Median</span></h1>
<p>Purpose: Uses a basic difference of Gaussian method for feature detection and a method which gives the difference between the original and a specified "Median" filter on a copy of the original image.
</p><p>How to: Difference of Gaussian needs the specification of 2 different Gaussian blurring radii and Difference from Median needs the specification of a Median kernel radius.
</p><p>Form: macro
</p><p>Status: maintenance active
</p><p>Future: Suggestions are welcome!
</p>
<hr />
<h1><span class="mw-headline" id="Hyperstack_Color_Coding">Hyperstack Color Coding</span></h1>
<p>Purpose: This macro enables the color coding of the time or volume dimension in stacks and hyperstacks. Multi-channels need to be split up before color coding can be done. The macro is based on the idea of the plugin from Kota Miura and Johannes Schindelin. In contrast to the latter, it keeps the coded stack besides the creation of an additional color-coded z-projection.
</p><p>How to: Given that you start with a hyperstack, you can choose between time and volume to be color coded. You can choose to create a z-projection by choosing from different projection types (as available in the ImageJ "Z-Project" function). Furthermore, a separated calibration bar can be created which will be horizontal for coded time stacks and vertical for coded volume stacks.
</p><p>Form: macro
</p><p>Status: maintenance active
</p><p>Future: Suggestions are welcome!
</p>
<hr />
<h1><span class="mw-headline" id="Neighbor_Analysis">Neighbor Analysis</span></h1>
<p>Purpose: This macro enables the color coding of particles in an 8-bit binary image according to the number of neighbors of each individual particle. Depending on the method chosen, different neighbor particles will be considered during the analysis.
</p><p>How to: Specify the analysis parameters (same input as for "Analyze Particles..."), choose if you want to include an initial watershed separation of the particles in the starting image and select if you want to display a calibration bar in addition to the analysis output. According to the calibration bar you can interpret the color coding. Mouse hovering over the colored particles enables you to see the respective number of neighbors in the ImageJ/Fiji main window as the number behind "index=".
</p><p>Methods: "Voronoi" analyzes the paticles according to the directly correlated voronoi map. "UEP Voronoi" uses the voronoi map from the ultimate eroded points of the particles. This might underestimate the real number of neighbors and is rather suitable for roundish structures. "Centroid Neighborhood" analyzes an area corresponding to a circle with the specified neighborhood radius around the centroid of each particle. "Particle Neighborhood" analyzes also an area around each particle with the specified radius as distance to the particle border.
</p><p><a href="File:NeighborAnalysis.png" class="image"><img alt="NeighborAnalysis.png" src="_images/f/f5/NeighborAnalysis.png" width="750" height="577" /></a>
</p><p>Form: macro
</p><p>Status: maintenance active
</p><p>Future: Suggestions are welcome!
</p>
<hr />
<h1><span class="mw-headline" id="2D_Particle_Distribution">2D Particle Distribution</span></h1>
<p>(<b>formerly: Distribution Analysis</b>, name changed due to redundency with BoneJ function naming)
</p><p>Purpose: This macro statistically determines if particles (according to their ultimate eroded point, UEP) in a 2D image are likely to be randomly distributed, self-avoiding or build clusters.
</p><p>How to: Starting with a binary image the setup dialog allows similar as the "Analyze Particles" to exclude particles by size and circularity as well as edge touching particles and include holes. The evaluation can be based on the mean nearest neighbor distance or the median nearest neighbor distance. The latter is suitable to better minimize the influence of outliers. Finally, the confidence interval of the statistical evaluation can be chosen between 95%, 99% and 99.9%.
</p><p>Method: The UEPs of the particles are generated and the nearest neighbor distance is determined for each particle. According to particle number and analyzed area the theoretical nearest neighbor distance is calculated using the formula: 0.5*sqrt(area/n) (according to J. Russ, The Image Processing Handbook, 2010, 6th Edition). This assumption ignores differences in particle size, so far. 
It is assumed that in the case of normally distributed particles, the mean equals the median. Thus, the method is implemented for the comparison of both, mean and median, from the assumption with the measured values. The measured (mean or median) nearest neighbour distance is statistically compared to the theoretical one. Therefore, first a suitable test method is determined according to the homogeneity of the variance using an F-Test. This finally decides about the use of either a Student's T-Test or a Welch Test for the final statistical evaluation.
</p><p><b>BE AWARE:</b> This tool estimates the type of clustering or exclusion since it does not take non-isotropic shape into account and WORKS ONLY on complete, rectangular images and NOT inside irregular ROIs. This might be changed in future.
</p><p><a href="File:DistributionAnalysis.png" class="image"><img alt="DistributionAnalysis.png" src="_images/d/d3/DistributionAnalysis.png" width="750" height="577" /></a>
</p><p>Form: macro
</p><p>Status: maintenance active
</p><p>Future: Suggestions are welcome!
</p>
<hr />
<h1><span class="mw-headline" id="SSIDC_Cluster_Indicator">SSIDC Cluster Indicator</span></h1>
<p>Meaning: Shape and size invariant DBSCAN based clustering
</p><p>Pronounce: S-SID C like "acid" C &#160;;-)
</p><p>Purpose: Indicating clusters of binary image objects after segmentation based on a shape and size invariant density based clustering <a rel="nofollow" class="external text" href="https://de.wikipedia.org/wiki/DBSCAN">DBSCAN</a>
</p><p>Advantage and HowTo: the algorithm detects clusters of any size, shape and number! The user does not need to have any prior knowledge or estimation of a number of clusters (as for e.g. k-means). 
The only input needed is the isotropic distance (in pixel) the user wants (epsilon in DBSCAN) to check around each object and a desired minimum density (number of objects inside the given distance). The algorithm reaches out equidistantly from the object shape. Therefore, amorphous shapes of particles do not matter. Furthermore, the size is not relevant, since the distance is taken from the outside of the object.
If size and shape should be ignored, the plugin can be run on the thresholded (min=1 max=255) ultimate points of the binary objects [►Process ►Binary ►Ultimate Points]
Clusters are also detected in an overlapping but still separate manner if some objects might belong to several clusters but do not belong to their core points.
</p><p>Output: The output is on purpose very sparse and gives only the ImageJ ROI Manager. From there cluster numbers and individual amount of objects per cluster can easily be analyzed e.g. using a macro on the ROI manager and the corresponding image 
</p><p>Application: The algorithm was already successfully applied in the quantification of clusters from different cell populations in microscopic mouse retina samples [Link once the manuscript is accepted and published]
</p><p>Limitation: works on 2D binary images only and does not detect clusters inside other clusters
</p>
<h1><span class="mw-headline" id="Cluster_Indicator">Cluster Indicator</span></h1>
<p>(depricated)
</p><p>Purpose: The "Cluster Indicator" is thought to detect local particle clusters in a binary image. Different particle sizes can be taken into account.
</p><p>How To: Choose a cluster detector size as a circle radius in pixels. 
The density (as a x-fold value) enables to adjust the sensitivity because found clusters are only accepted as a cluster when their density of neighbor distances is at least x-fold of the average neighbor distance in the complete image. 
Two possible methods can be chosen: 
</p><p>1.) "average NND" uses the inverted 32-bit Voronoi image as measure of the between-particle (border-to-border) distances to all of their neighbors. This accounts for differences in particle size as well as shape. The average neighbor distance is taken to intensity code the centroid point in the evaluation image.
</p><p>2.) "centroid NND" uses the ultimate eroded point map and intensity codes the points according to their nearest neighbor distance. This method is faster especially for big images with many particles but neglects differences in particle size and shape. Therefore, might only be applicable if all particles are equal in size and shape.
</p><p>Each individual cluster finding process is aborted if a local cluster was not found after the specified number of maximal iterations. Those aborted clusters can be shown as blue ROIs in the image if desired (see checkbox).
</p><p>Clusters overlapping (at least 1 pixel) can also be fused to one cluster if specified so by the respective checkbox.
</p><p>Consider that the detector size as well as density settings influence if a cluster is found and finally accepted as a cluster. This on the one hand leads to a certain bias but should enable the user to search for clusters of different sizes and densities.
</p><p><a href="File:ClusterIndicator.png" class="image"><img alt="ClusterIndicator.png" src="_images/3/3e/ClusterIndicator.png" width="750" height="563" /></a>
</p><p>Method: Circle ROIs of the specified size are initially distributed with sufficient overlap to cover the complete image. The cluster finding process is done according to the mean shift method towards the center of mass of clusters. The latter is influenced by particle number, size and neighbor distance.
</p><p>Form: plugin, recordable
</p><p>Status: stable, not further actively maintained 
</p>
<hr />
<h1><span class="mw-headline" id="Skeleton_Length_.28corrected.29">Skeleton Length (corrected)</span></h1>
<p>Status: deprecated due to incorrect calculation
</p><p>Please rather use the <a rel="nofollow" class="external text" href="AnalyzeSkeleton">Analyze Skeleton 2D/3D</a> which is shipped with Fiji
</p>
<hr />
<h1><span class="mw-headline" id="Nearest_Neighbor_Indicator_.28Separate_Tool.29">Nearest Neighbor Indicator (Separate Tool)</span></h1>
<p>Purpose/How to: This tool enables the user to click in any feature in a binary image to identify all neigbors and the nearest neighbor of this feature. Therefore, the tool needs to be activated. Then any click will lead to a new calculation of the neighbors depending on the location clicked on.
</p><p>Output: A copy of the original image is created with the particle of interest (POI) in red, neighbors in blue and the nearest neighbor in yellow. If more then one neighbor has the same distance to the POI all neighbors with that distance will be indicated in yellow.
</p><p>Method: As measure for the distance between the particles the minimum separation distance is taken by analysis of the intensity coded Voronoi cell algorithm of ImageJ. The lowest non-background intensity is used to indicate the nearest neighbor.
</p><p><a href="File:NearestNeighborIndicator.png" class="image"><img alt="NearestNeighborIndicator.png" src="_images/7/76/NearestNeighborIndicator.png" width="750" height="563" /></a>
</p><p>Form: macro
</p><p>Status: maintenance active
</p><p>Future: Suggestions are welcome!
</p>
<hr />
<h1><span class="mw-headline" id="Gaussian_weighted_Median_filter">Gaussian weighted Median filter</span></h1>
<p>(separate plugin under <span><em><span style="border-bottom:1px dotted #ccc;"> Plugins </span>&#160;&#8250; <span style="border-bottom:1px dotted #ccc;"> BioVoxxel</span></em></span>)
</p><p>Purpose/How to: This filter is basically a normal median filter (as in ImageJ/Fiji) but with a weighted filter matrix. The radius is given in pixels. The weight is determined automatically by a 2D gaussian function (approximated to integer values) over the size of the filter grid. Thus, pixel closer to the filter center get a higher weight compared to more distant ones. This reduces the intensity homogenizing effect from a normal median filter but increases the edge-perservation of features.
</p><p>Output: The filter will be applied directly on the input image. It is undoable (by pressing [z]) and will be recorded by the macro recorder.
</p><p>Limitation: So far, the filter is only applicable on 8-bit and 16-bit single images.
</p><p>Installation: Part of the BioVoxxel update site in Fiji and can be found under <span><em><span style="border-bottom:1px dotted #ccc;"> Plugins </span>&#160;&#8250; <span style="border-bottom:1px dotted #ccc;"> BioVoxxel</span></em></span>
</p><p>Form: plugin, recordable
</p><p>Status: maintenance active
</p><p>Future: Will be adjusted für 32-bit float-type images as well as RGB images and stacks. Suggestions are welcome!
</p>
<hr />
<h1><span class="mw-headline" id="Enhance_True_Color_Contrast">Enhance True Color Contrast</span></h1>
<p>(separate plugin under <span><em><span style="border-bottom:1px dotted #ccc;"> Plugins </span>&#160;&#8250; <span style="border-bottom:1px dotted #ccc;"> BioVoxxel</span></em></span>)
</p><p>Purpose: This image filter enhances the contrast of true color images similar to the method Enhance Contrast in Fiji. If the latter would be applied to true color images this leads to a change in color values and saturation. This unwanted effects are eliminated by the recordable "Enhance True Color Contrast" plugin. It preserves color tone and saturation while enhancing the contrast in the brightness channel of the HSB color space. This is done using high precision float value calculation and not by a simple conversion o fthe image to HSB color space as available in ImageJ/Fiji. The latter would lead to a loss in quality since due to conversion and back-conversion to RGB.
</p><p>How to: The user can key in a percentage of saturated pixels as in the "Enhance Contrast" function and has a preview option.
</p><p>Remarks: is recordable and works with stacks
</p><p>Form: plugin, recordable
</p><p>Status: maintenance active
</p>
<hr />
<h1><span class="mw-headline" id="Mode_and_Differential_Limited_Mean_Binarization">Mode and Differential Limited Mean Binarization</span></h1>
<p>(separate plugin under <span><em><span style="border-bottom:1px dotted #ccc;"> Plugins </span>&#160;&#8250; <span style="border-bottom:1px dotted #ccc;"> BioVoxxel</span></em></span>)
</p><p>Purpose: The mode-limited mean (MoLiM) and the differential-limited mean (DiLiM) are two binarization algorithms which initially limit the image histogram according to its mode value (MoLiM) or its mode, an initial mean or the median (DiLiM). A more detailed description can be found under:
</p><p><a rel="nofollow" class="external text" href="http://www.cscjournals.org/library/manuscriptinfo.php?mc=IJIP-829">Qualitative and Quantitative Evaluation of Two New Histogram Limiting Binarization Algorithms</a>.
J. Brocher, Int. J. Image Process. 8(2), 2014 pp. 30-48
</p><p>How To: the user can choose to use the differential threshold determination or the forced mode-limited method if "differential limitation" is off.
The algorithm assumes that the features occupy less than 50% of the images space independent if they are bright on a dark background or vice versa. For the opposite case one would need to invert the final output image. 
The limitation step eliminates all intensity information in the histogram up to the limit (mode, mean or median) and calculates a new mean value which is taken as final threshold. "Force to smaller partition" anables to extract the pixels which occupy rather the smaller histogram partition besides the limit.
</p><p>Download: Part of the BioVoxxel update site in Fiji and can be found under <span><em><span style="border-bottom:1px dotted #ccc;"> Plugins </span>&#160;&#8250; <span style="border-bottom:1px dotted #ccc;"> BioVoxxel</span></em></span>
</p><p>Form: plugin, recordable
</p><p>Status: maintenance active
</p><p>Future: Will be implemented for stacks as well.
</p><p><br />
</p>
<hr />
<hr />
<p><br />
All BioVoxxel Macros were developed by <a href="User:BioVoxxel" class="mw-redirect" title="User:BioVoxxel">Jan Brocher</a>
</p><p>The macros can be freely used, redistributed and changed according to the BSD-3 License. 
</p><p>For questions, comments and suggestions please contact: jan.brocher(at)biovoxxel.de
</p><p>There is NO WARRANTY of functionality for those macros.
</p><p>In no event neither <a href="User:BioVoxxel" class="mw-redirect" title="User:BioVoxxel">Jan Brocher</a> nor BioVoxxel shall be liable to any party for direct, indirect, special, incidental, or consequential damages or data loss of any kind arising out of the use of this software and its documentation, even if advised of the possibility thereof.
</p>
<!-- 
NewPP limit report
Cached time: 20200713064642
Cache expiry: 86400
Dynamic content: false
CPU time usage: 0.104 seconds
Real time usage: 0.112 seconds
Preprocessor visited node count: 854/1000000
Preprocessor generated node count: 4642/1000000
Post‐expand include size: 5098/2097152 bytes
Template argument size: 1206/2097152 bytes
Highest expansion depth: 6/40
Expensive parser function count: 0/3
-->

<!-- 
Transclusion expansion time report (%,ms,calls,template)
100.00%   39.802      1 - -total
 51.17%   20.365     11 - Template:Bc
 39.54%   15.738      1 - Template:Infobox
 31.13%   12.392      4 - Template:Person
 12.00%    4.778     11 - Template:Arrow
-->
</div><div class="printfooter">
Retrieved from "<a dir="ltr" href="index.php?title=BioVoxxel_Toolbox&amp;oldid=42581">http://imagej.net/index.php?title=BioVoxxel_Toolbox&amp;oldid=42581</a>"</div>
							</div>

			<div id="footer">
				<p> This page was last modified on 12 February 2020, at 11:48.</p><ul><li><a href="ImageJ:Privacy_policy" title="ImageJ:Privacy policy">Privacy policy</a></li><li><a href="ImageJ:About" class="mw-redirect" title="ImageJ:About">About ImageJ</a></li><li><a href="Imprint" title="Imprint">Imprint</a></li><li><a href="index.php?title=BioVoxxel_Toolbox&amp;mobileaction=toggle_view_mobile" class="noprint stopMobileRedirectToggle">Mobile view</a></li></ul>			</div>

			<div id="catlinks" class="catlinks" data-mw="interface"><div id="mw-normal-catlinks" class="mw-normal-catlinks"><a href="Special:Categories" title="Special:Categories">Categories</a>: <ul><li><a href="index.php?title=Category:Pages_using_duplicate_arguments_in_template_calls&amp;action=edit&amp;redlink=1" class="new" title="Category:Pages using duplicate arguments in template calls (page does not exist)">Pages using duplicate arguments in template calls</a></li><li><a href="Category:Particle_analysis" title="Category:Particle analysis">Particle analysis</a></li></ul></div></div>		</div>

		<div id="bottom-wrap">
		</div>
		<script>(window.RLQ=window.RLQ||[]).push(function(){mw.loader.load(["ext.fancytree","ext.suckerfish","mediawiki.toc","mediawiki.action.view.postEdit","site","mediawiki.user","mediawiki.hidpi","mediawiki.page.ready","mediawiki.searchSuggest","ext.SimpleTooltip"]);});</script><script>(window.RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgBackendResponseTime":302});});</script>
		</body>
		</html>
		